{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a932b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from models import gptv1\n",
    "\n",
    "config = gptv1.GPTv1Config(device=\"mps\", batch_size=16, block_size=256, n_heads=6)\n",
    "device = config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3635c630",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../../data/freud/interpretation-of-dreams.txt\"\n",
    "input_file = open(filepath, 'r', encoding='utf-8')\n",
    "raw_text = input_file.read()\n",
    "input_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "798b822d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenDictionary(token_set=['\\n', ' ', '!', '&', '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '·', 'À', 'Â', 'Æ', 'É', 'Ü', 'à', 'ä', 'æ', 'ç', 'è', 'é', 'ê', 'î', 'ï', 'ó', 'ô', 'û', 'ü', 'Œ', 'œ', '̓', 'Ψ', 'έ', 'ν', 'ς', 'υ', 'χ', '–', '—', '‘', '’', '“', '”', 'e ', 'th', ' th', 's ', 'in', 're', ' the ', 'on', ' a', 'er', 't ', 'd ', 'en', 'of', 'ti', 'y ', 'or', 'to', ', ', 'an', 'ou', 'rea', 'ch', '. ', 'is ', 'ing', 'tion', 'al', 'ar', 'wh', 'ream', 'dream', 'is', ' s', ' an', 'at', 'es', 'ed ', 'of ', 'om', 'it', 'ha', 'to ', 'er ', 'con', 'of the ', 'el', 'whi', 'ation', 'ing ', 'which', 'for', 'no', 'es ', 'ed', 'ec', ' a ', 'he ', 'si', 'in ', 'em', 'ur', 'st', 'ic', 'ly ', 'ent', ' and ', 'ex', 'gh', 'at ', 've ', 'res', 'wi', 'in the ', 'dream ', 'which ', 'ac', 'll', 'le ', 'wa', 'I ', 'ow', 'en ', 'ul', 'us', 'os', 'un', 'im', 'o ', 'be', 'al ', 'with', 'pl', 'fr', 'as', 'it ', 'ro', 'ma', 'e th', ' that ', 'ation ', '. T', ' this ', 'ough', 'if', 'ver', 'tr', 'ir', 'de', 'on ', 'il', 'pres', 'ter', 'a ', 'ent ', 'be ', 'le', 'per', 'ta', 'our', 'have ', 'tion ', 'ce ', 'to the ', 'from', ', and ', 'oth', 'ish', 'am', 'not ', ' as ', 'su', 'pro', 'ol', 'ere', 'com', 'we ', 'ab', 'sy', 'ci', 'all', 'dis', 'his ', 'ce', 'my ', 'an ', 'se', 'has ', '.\\n', 'qu', ' that', '. I', ' and', 'pp', '. The ', 'one ', 'ts ', 'was ', 'ere ', 'ear', 'or ', 'bu', ' ar', 'up', 'me', 'sych', ' though', 'li', 'rec', 'n ', 'oun', 'by ', 'cc', 's, ', 'psych', 'ri', ' the', 'par', 'di', 'e the ', 'and ', 'sel', 'ly', 'tic', '; ', 'by', 'us ', 'pa', '” ', 'pre', 'with ', 'had ', ' as', 'oul', 'ne', 'ted ', 'for ', 'ag', 'ess', 'cont', 'now', 'cons', 't the ', 'wish', 'tim', 'ens', 'll ', 'ob', 'and', 'id', 'k ', 'its ', 'ould ', 'ad', 'man', 'other ', 'how', ' are ', 'tu', 'tw', 'self', ', the ', ', and', 'ous ', 'ay', 'ong', 'form', 'ep', 'ind', 'are ', 'der', 'ity ', 'ful', 'uc', 'ess ', 'fo', 'ten', ' ac', 'our ', 'psychic', 'ig', ' su', 'og', 'ph', 'ous', ' an ', 'ke ', 'wor', 'sion', ' the s', 'ra', 'may ', 'et', 'been ', 'e, ', 'pos', 'inter', 'mor', 'ame ', 'him', 'consci', 'jec', 'po', ': ', 'present', 'sion ', 'from ', 'ev', 'ch ', 'bec', 'ell', 'ien', 'ter ', ' al', 'of the dream', 'ever', 'on the ', 'e of ', 'mo', 'as ', 'igh', 'ing the ', 'cl', '. A', 'able ', 'ain', 'ations ', 'for the ', 'dreams ', 'but ', 'fac', 'other', ' that the ', 'ther', 'of a ', 'ea', 'um', 'who ', 'from the ', 'co', 'fa', 'vi', 'occ', 'ther ', 'chil', 'ate ', 'eri', 'so ', 'ally ', 'fir', 'her ', 'ble ', 'fere', 'to be ', 'by the ', 'mat', 'bo', 'ome ', 'ment', 'to s', 'ust ', 'pr', 'wak', 'nec', ' at', 'plac', 'out ', 'The ', ' a s', 'ory ', 'ese ', 'y, ', 'in the dream', 'so', 'bl', 'fe', 'int', 'ca', 'tiv', 'of the dream ', 'str', 'interpre', 'me ', '’s ', 'pec', 's the ', 's of ', 'ren', ' am', 'feren', 'rel', 'pers', 'ang', 'rough', 'tur', 'ing s', 'with the ', 'sh', 'red ', ' ab', 'do', 'know', 'leep', '. W', 'psychic ', 'iv', 'ff', 'only ', 'ost ', 'Bu', 'st ', 'de ', 'aly', 'ar ', 'cer', 'ance ', 'lif', 'mem', 'it is ', 'ose ', 'tak', ' these ', 'ord', 'child', 'interpret', 'op', 'llow', ', which ', ' them', 'ir ', 'must ', 'ement', 'of this ', 'no ', 'cas', 'more ', 'mean', 'ment ', 'self ', 'ser', 'des', 'min', ': “', 'most ', 'connec', '. I ', '. Th', 'dif', '_ ', ' app', 'tive ', 'tions ', 'oo', 'w ', 'would ', 'expl', '. It ', 'ard', 'can ', 'fl', 'all ', 'cit', 'alys', 'lit', 'thing ', '. H', 'materi', 'et ', 'of s', 'ant', 'ed to ', '] ', 'her', 'enti', '.” ', ' thought', 'ust', 'follow', 'first ', 'ted', 'very ', 'fic', 'read', 'expres', 'ay ', ' at ', 'fact', 'ite ', ', as ', 'lat', ' sh', 'cep', 'represent', 'dur', ' all', 'two ', 'ence ', ' their ', '. Bu', 'ans', ' there ', 'por', 'au', 'ide', ' the dream ', 't of ', 'exam', 'over', 'year', 'es, ', 'compl', 'tain', 'f ', 'pe', 'the ', 'ical ', ' of ', 'gr', 'I have ', 'cor', 'ome', 'my', 'who', ' thoughts ', ' through', 'what ', 'in the dream ', 'fur', 'ill', 'ure ', 'olog', 'not', 'occur', 'ary ', 'ated ', 'conscious', ' they ', ' se', 'content', 'timul', 'person', ' af', ' ag', 'pati', 'tic ', 'under', 'es the ', 'day', 'reg', 'proc', 'ud', 'way', 'bel', 'she ', 'exper', 'conscious ', 'duc', 'ual ', 'ant ', 'pic', ', but ', 'frien', 'ation of ', 'fulf', 'fin', 'pu', ' acc', 'will ', 'ound ', 'go', 'ement ', 'impres', 'sible ', 'wish ', 'can', 'ness ', 'char', 'ity', 'part ', 'I am', 'ces ', 'tle ', 'were ', 's to ', 'out', '. O', 'ed by ', 'own ', 'ed the ', 'sub', 'contr', 'se ', 'you', ') ', 'end', ' ad', 'real', 'which is ', 'long', 'sti', ' at the ', 'est ', 'ely ', 'app', 'grea', 'ure', 'but', 'en the ', 'trans', 'experien', 'cour', 'cri', 'gen', 'p. ', 'in a ', 'into the ', 'to a ', 'use ', 'ist', '. In', 'we have ', 'now ', 'time ', 'however', 'nif', 'orig', '. F', 'which the ', 'fore', 'ffec', 'ise ', 'ive ', 'pon', 'is the ', 'twe', 'do ', 'betwe', 'content ', 'dreams', 'objec', 'tly ', '. S', 'ed, ', 'does ', 'ain ', 'ner', 'one', 'fore ', 'dist', '. We ', 'ge ', 'es of ', 'ight ', 'mp', 'at the ', '. This ', 'ing to ', 'excit', 'al s', 'om ', ' activ', 'into ', 'only', 'while ', 'ation of the ', 'sur', '.\\nI', 'red', 'little ', 'mar', 'ge', 'same ', 'ue ', 'if ', 'beca', 'consi', 'ful ', 'feel', 'trea', '._', 'inc', 'em ', 'has been ', 'him ', 'eas', 'way ', 'ound', '. But ', 'sig', 'giv', 'nat', 'ver ', ' there', 'emp', 'made ', 'upon ', 'material ', 'fulfil', 'day ', 'element', 'fer', 'when ', ' another ', 'br', ' all ', '. M', 'ed by the ', 'like ', 'well', 'd of ', 'main', 'may be ', 'a s', 'lo', 's of the ', 'sa', 'been', '.”', 'ves ', 'ber', 'ten ', 'ready ', 'ke', 'med', 'ast ', 'cap', 'chang', 'ari', 'ed in ', 'even ', 'ting ', 'und', 'ques', 'mu', 'alysis ', 'I am ', 'show', 'in this ', 'tis', 'too', 'differen', 'here ', ', however', 'charac', 'had', 'opp', ' she ', ' any ', 'e that ', 'produc', 'fre', 'which are ', ' as a ', 'ight', 'ogn', 'secon', 'tat', 'place ', 'inv', 'llec', ', and the ', ' also ', 'life ', '.[', 'hy', 've', 'take ', ' thought ', 'origin', '(p. ', 'la', 'ps ', 'tain ', 'found ', ' those ', 'anc', 'ations', 'lear', 'tion of the ', 'many ', '. It is ', '. On', 'just', 'pur', 'contin', 'poin', 'becom', 'serv', 'nific', 'does not ', 'I sh', 'call', 'fi', 'th ', 'ties ', 'ings ', '.\\nThe ', ' appear', 'explan', ' thoughts', 'ing, ', ', that ', '; the ', '? ', 'king ', ' as the ', '. He ', 'bro', 'm ', 'val', 'though', 'ack ', 'comm', 'recogn', 'manif', ' the same ', 'vis', 'ance', 'ult', 'impression', 'subjec', 'ow ', 'every ', 'during the ', 'hi', 'man ', 'sc', 'vel', 'til', 'condi', 'ass', 'soci', 'cens', 'den', 'he', 'itself ', 'own', 'tion of ', 'direc', 'gu', ' thin', 'unc', 'termin', 'posi', 'become ', 'life', 'pictu', 'est', 'psycholog', ',” ', 'ey', 'find', 'mis', 'in s', 'remain', 'org', 'out the ', 'ation, ', 'ems ', 'percep', 'possible ', ', a ', 'hoo', 'inde', 't to ', 'old ', ' sub', 'patient', '.”\\n', ' thus ', 'I was ', ' and the ', 'ong ', 'respon', 'dea', 'press', 'omething ', 'men', 'num', 'sens', 'we are ', 'interpretation ', 'cannot ', 'tow', 'concer', 'emo', 'exual ', 'I had ', 'up ', 'pain', 'waken', '..', 'cus', 'dec', 'ks ', 'y the ', ', wh', 'is a ', 'unconscious ', 'trac', 'lea', ' them ', 'case ', ' activity ', 'dem', 'id ', 'thor', 'imp', 'wish-', 'flu', 'youn', 'of my ', 'ish ', 'struc', 'taken ', 'timuli', ' after', 'continu', 'young', '(_', 'ness', 'make ', 'vers', 'tri', 'person ', 'friend ', 'fu', 'ie', 'less ', 'might ', 's and ', 'once ', 'often ', 'is, ', 'ently ', 'without ', 'prob', 'old', 'occa', 'memor', 'process', 'because ', 'purpos', 'mind', 'being ', 'word', ' again', 'consider', 's, and ', 'vid', 'reas', 'ely', 'in which ', 'resul', 'comp', ' about ', 'diffic', 'great ', ', however, ', 'cr'], idx_to_token={0: '\\n', 1: ' ', 2: '!', 3: '&', 4: '(', 5: ')', 6: ',', 7: '-', 8: '.', 9: '0', 10: '1', 11: '2', 12: '3', 13: '4', 14: '5', 15: '6', 16: '7', 17: '8', 18: '9', 19: ':', 20: ';', 21: '=', 22: '?', 23: 'A', 24: 'B', 25: 'C', 26: 'D', 27: 'E', 28: 'F', 29: 'G', 30: 'H', 31: 'I', 32: 'J', 33: 'K', 34: 'L', 35: 'M', 36: 'N', 37: 'O', 38: 'P', 39: 'Q', 40: 'R', 41: 'S', 42: 'T', 43: 'U', 44: 'V', 45: 'W', 46: 'X', 47: 'Y', 48: 'Z', 49: '[', 50: ']', 51: '_', 52: 'a', 53: 'b', 54: 'c', 55: 'd', 56: 'e', 57: 'f', 58: 'g', 59: 'h', 60: 'i', 61: 'j', 62: 'k', 63: 'l', 64: 'm', 65: 'n', 66: 'o', 67: 'p', 68: 'q', 69: 'r', 70: 's', 71: 't', 72: 'u', 73: 'v', 74: 'w', 75: 'x', 76: 'y', 77: 'z', 78: '·', 79: 'À', 80: 'Â', 81: 'Æ', 82: 'É', 83: 'Ü', 84: 'à', 85: 'ä', 86: 'æ', 87: 'ç', 88: 'è', 89: 'é', 90: 'ê', 91: 'î', 92: 'ï', 93: 'ó', 94: 'ô', 95: 'û', 96: 'ü', 97: 'Œ', 98: 'œ', 99: '̓', 100: 'Ψ', 101: 'έ', 102: 'ν', 103: 'ς', 104: 'υ', 105: 'χ', 106: '–', 107: '—', 108: '‘', 109: '’', 110: '“', 111: '”', 112: 'e ', 113: 'th', 114: ' th', 115: 's ', 116: 'in', 117: 're', 118: ' the ', 119: 'on', 120: ' a', 121: 'er', 122: 't ', 123: 'd ', 124: 'en', 125: 'of', 126: 'ti', 127: 'y ', 128: 'or', 129: 'to', 130: ', ', 131: 'an', 132: 'ou', 133: 'rea', 134: 'ch', 135: '. ', 136: 'is ', 137: 'ing', 138: 'tion', 139: 'al', 140: 'ar', 141: 'wh', 142: 'ream', 143: 'dream', 144: 'is', 145: ' s', 146: ' an', 147: 'at', 148: 'es', 149: 'ed ', 150: 'of ', 151: 'om', 152: 'it', 153: 'ha', 154: 'to ', 155: 'er ', 156: 'con', 157: 'of the ', 158: 'el', 159: 'whi', 160: 'ation', 161: 'ing ', 162: 'which', 163: 'for', 164: 'no', 165: 'es ', 166: 'ed', 167: 'ec', 168: ' a ', 169: 'he ', 170: 'si', 171: 'in ', 172: 'em', 173: 'ur', 174: 'st', 175: 'ic', 176: 'ly ', 177: 'ent', 178: ' and ', 179: 'ex', 180: 'gh', 181: 'at ', 182: 've ', 183: 'res', 184: 'wi', 185: 'in the ', 186: 'dream ', 187: 'which ', 188: 'ac', 189: 'll', 190: 'le ', 191: 'wa', 192: 'I ', 193: 'ow', 194: 'en ', 195: 'ul', 196: 'us', 197: 'os', 198: 'un', 199: 'im', 200: 'o ', 201: 'be', 202: 'al ', 203: 'with', 204: 'pl', 205: 'fr', 206: 'as', 207: 'it ', 208: 'ro', 209: 'ma', 210: 'e th', 211: ' that ', 212: 'ation ', 213: '. T', 214: ' this ', 215: 'ough', 216: 'if', 217: 'ver', 218: 'tr', 219: 'ir', 220: 'de', 221: 'on ', 222: 'il', 223: 'pres', 224: 'ter', 225: 'a ', 226: 'ent ', 227: 'be ', 228: 'le', 229: 'per', 230: 'ta', 231: 'our', 232: 'have ', 233: 'tion ', 234: 'ce ', 235: 'to the ', 236: 'from', 237: ', and ', 238: 'oth', 239: 'ish', 240: 'am', 241: 'not ', 242: ' as ', 243: 'su', 244: 'pro', 245: 'ol', 246: 'ere', 247: 'com', 248: 'we ', 249: 'ab', 250: 'sy', 251: 'ci', 252: 'all', 253: 'dis', 254: 'his ', 255: 'ce', 256: 'my ', 257: 'an ', 258: 'se', 259: 'has ', 260: '.\\n', 261: 'qu', 262: ' that', 263: '. I', 264: ' and', 265: 'pp', 266: '. The ', 267: 'one ', 268: 'ts ', 269: 'was ', 270: 'ere ', 271: 'ear', 272: 'or ', 273: 'bu', 274: ' ar', 275: 'up', 276: 'me', 277: 'sych', 278: ' though', 279: 'li', 280: 'rec', 281: 'n ', 282: 'oun', 283: 'by ', 284: 'cc', 285: 's, ', 286: 'psych', 287: 'ri', 288: ' the', 289: 'par', 290: 'di', 291: 'e the ', 292: 'and ', 293: 'sel', 294: 'ly', 295: 'tic', 296: '; ', 297: 'by', 298: 'us ', 299: 'pa', 300: '” ', 301: 'pre', 302: 'with ', 303: 'had ', 304: ' as', 305: 'oul', 306: 'ne', 307: 'ted ', 308: 'for ', 309: 'ag', 310: 'ess', 311: 'cont', 312: 'now', 313: 'cons', 314: 't the ', 315: 'wish', 316: 'tim', 317: 'ens', 318: 'll ', 319: 'ob', 320: 'and', 321: 'id', 322: 'k ', 323: 'its ', 324: 'ould ', 325: 'ad', 326: 'man', 327: 'other ', 328: 'how', 329: ' are ', 330: 'tu', 331: 'tw', 332: 'self', 333: ', the ', 334: ', and', 335: 'ous ', 336: 'ay', 337: 'ong', 338: 'form', 339: 'ep', 340: 'ind', 341: 'are ', 342: 'der', 343: 'ity ', 344: 'ful', 345: 'uc', 346: 'ess ', 347: 'fo', 348: 'ten', 349: ' ac', 350: 'our ', 351: 'psychic', 352: 'ig', 353: ' su', 354: 'og', 355: 'ph', 356: 'ous', 357: ' an ', 358: 'ke ', 359: 'wor', 360: 'sion', 361: ' the s', 362: 'ra', 363: 'may ', 364: 'et', 365: 'been ', 366: 'e, ', 367: 'pos', 368: 'inter', 369: 'mor', 370: 'ame ', 371: 'him', 372: 'consci', 373: 'jec', 374: 'po', 375: ': ', 376: 'present', 377: 'sion ', 378: 'from ', 379: 'ev', 380: 'ch ', 381: 'bec', 382: 'ell', 383: 'ien', 384: 'ter ', 385: ' al', 386: 'of the dream', 387: 'ever', 388: 'on the ', 389: 'e of ', 390: 'mo', 391: 'as ', 392: 'igh', 393: 'ing the ', 394: 'cl', 395: '. A', 396: 'able ', 397: 'ain', 398: 'ations ', 399: 'for the ', 400: 'dreams ', 401: 'but ', 402: 'fac', 403: 'other', 404: ' that the ', 405: 'ther', 406: 'of a ', 407: 'ea', 408: 'um', 409: 'who ', 410: 'from the ', 411: 'co', 412: 'fa', 413: 'vi', 414: 'occ', 415: 'ther ', 416: 'chil', 417: 'ate ', 418: 'eri', 419: 'so ', 420: 'ally ', 421: 'fir', 422: 'her ', 423: 'ble ', 424: 'fere', 425: 'to be ', 426: 'by the ', 427: 'mat', 428: 'bo', 429: 'ome ', 430: 'ment', 431: 'to s', 432: 'ust ', 433: 'pr', 434: 'wak', 435: 'nec', 436: ' at', 437: 'plac', 438: 'out ', 439: 'The ', 440: ' a s', 441: 'ory ', 442: 'ese ', 443: 'y, ', 444: 'in the dream', 445: 'so', 446: 'bl', 447: 'fe', 448: 'int', 449: 'ca', 450: 'tiv', 451: 'of the dream ', 452: 'str', 453: 'interpre', 454: 'me ', 455: '’s ', 456: 'pec', 457: 's the ', 458: 's of ', 459: 'ren', 460: ' am', 461: 'feren', 462: 'rel', 463: 'pers', 464: 'ang', 465: 'rough', 466: 'tur', 467: 'ing s', 468: 'with the ', 469: 'sh', 470: 'red ', 471: ' ab', 472: 'do', 473: 'know', 474: 'leep', 475: '. W', 476: 'psychic ', 477: 'iv', 478: 'ff', 479: 'only ', 480: 'ost ', 481: 'Bu', 482: 'st ', 483: 'de ', 484: 'aly', 485: 'ar ', 486: 'cer', 487: 'ance ', 488: 'lif', 489: 'mem', 490: 'it is ', 491: 'ose ', 492: 'tak', 493: ' these ', 494: 'ord', 495: 'child', 496: 'interpret', 497: 'op', 498: 'llow', 499: ', which ', 500: ' them', 501: 'ir ', 502: 'must ', 503: 'ement', 504: 'of this ', 505: 'no ', 506: 'cas', 507: 'more ', 508: 'mean', 509: 'ment ', 510: 'self ', 511: 'ser', 512: 'des', 513: 'min', 514: ': “', 515: 'most ', 516: 'connec', 517: '. I ', 518: '. Th', 519: 'dif', 520: '_ ', 521: ' app', 522: 'tive ', 523: 'tions ', 524: 'oo', 525: 'w ', 526: 'would ', 527: 'expl', 528: '. It ', 529: 'ard', 530: 'can ', 531: 'fl', 532: 'all ', 533: 'cit', 534: 'alys', 535: 'lit', 536: 'thing ', 537: '. H', 538: 'materi', 539: 'et ', 540: 'of s', 541: 'ant', 542: 'ed to ', 543: '] ', 544: 'her', 545: 'enti', 546: '.” ', 547: ' thought', 548: 'ust', 549: 'follow', 550: 'first ', 551: 'ted', 552: 'very ', 553: 'fic', 554: 'read', 555: 'expres', 556: 'ay ', 557: ' at ', 558: 'fact', 559: 'ite ', 560: ', as ', 561: 'lat', 562: ' sh', 563: 'cep', 564: 'represent', 565: 'dur', 566: ' all', 567: 'two ', 568: 'ence ', 569: ' their ', 570: '. Bu', 571: 'ans', 572: ' there ', 573: 'por', 574: 'au', 575: 'ide', 576: ' the dream ', 577: 't of ', 578: 'exam', 579: 'over', 580: 'year', 581: 'es, ', 582: 'compl', 583: 'tain', 584: 'f ', 585: 'pe', 586: 'the ', 587: 'ical ', 588: ' of ', 589: 'gr', 590: 'I have ', 591: 'cor', 592: 'ome', 593: 'my', 594: 'who', 595: ' thoughts ', 596: ' through', 597: 'what ', 598: 'in the dream ', 599: 'fur', 600: 'ill', 601: 'ure ', 602: 'olog', 603: 'not', 604: 'occur', 605: 'ary ', 606: 'ated ', 607: 'conscious', 608: ' they ', 609: ' se', 610: 'content', 611: 'timul', 612: 'person', 613: ' af', 614: ' ag', 615: 'pati', 616: 'tic ', 617: 'under', 618: 'es the ', 619: 'day', 620: 'reg', 621: 'proc', 622: 'ud', 623: 'way', 624: 'bel', 625: 'she ', 626: 'exper', 627: 'conscious ', 628: 'duc', 629: 'ual ', 630: 'ant ', 631: 'pic', 632: ', but ', 633: 'frien', 634: 'ation of ', 635: 'fulf', 636: 'fin', 637: 'pu', 638: ' acc', 639: 'will ', 640: 'ound ', 641: 'go', 642: 'ement ', 643: 'impres', 644: 'sible ', 645: 'wish ', 646: 'can', 647: 'ness ', 648: 'char', 649: 'ity', 650: 'part ', 651: 'I am', 652: 'ces ', 653: 'tle ', 654: 'were ', 655: 's to ', 656: 'out', 657: '. O', 658: 'ed by ', 659: 'own ', 660: 'ed the ', 661: 'sub', 662: 'contr', 663: 'se ', 664: 'you', 665: ') ', 666: 'end', 667: ' ad', 668: 'real', 669: 'which is ', 670: 'long', 671: 'sti', 672: ' at the ', 673: 'est ', 674: 'ely ', 675: 'app', 676: 'grea', 677: 'ure', 678: 'but', 679: 'en the ', 680: 'trans', 681: 'experien', 682: 'cour', 683: 'cri', 684: 'gen', 685: 'p. ', 686: 'in a ', 687: 'into the ', 688: 'to a ', 689: 'use ', 690: 'ist', 691: '. In', 692: 'we have ', 693: 'now ', 694: 'time ', 695: 'however', 696: 'nif', 697: 'orig', 698: '. F', 699: 'which the ', 700: 'fore', 701: 'ffec', 702: 'ise ', 703: 'ive ', 704: 'pon', 705: 'is the ', 706: 'twe', 707: 'do ', 708: 'betwe', 709: 'content ', 710: 'dreams', 711: 'objec', 712: 'tly ', 713: '. S', 714: 'ed, ', 715: 'does ', 716: 'ain ', 717: 'ner', 718: 'one', 719: 'fore ', 720: 'dist', 721: '. We ', 722: 'ge ', 723: 'es of ', 724: 'ight ', 725: 'mp', 726: 'at the ', 727: '. This ', 728: 'ing to ', 729: 'excit', 730: 'al s', 731: 'om ', 732: ' activ', 733: 'into ', 734: 'only', 735: 'while ', 736: 'ation of the ', 737: 'sur', 738: '.\\nI', 739: 'red', 740: 'little ', 741: 'mar', 742: 'ge', 743: 'same ', 744: 'ue ', 745: 'if ', 746: 'beca', 747: 'consi', 748: 'ful ', 749: 'feel', 750: 'trea', 751: '._', 752: 'inc', 753: 'em ', 754: 'has been ', 755: 'him ', 756: 'eas', 757: 'way ', 758: 'ound', 759: '. But ', 760: 'sig', 761: 'giv', 762: 'nat', 763: 'ver ', 764: ' there', 765: 'emp', 766: 'made ', 767: 'upon ', 768: 'material ', 769: 'fulfil', 770: 'day ', 771: 'element', 772: 'fer', 773: 'when ', 774: ' another ', 775: 'br', 776: ' all ', 777: '. M', 778: 'ed by the ', 779: 'like ', 780: 'well', 781: 'd of ', 782: 'main', 783: 'may be ', 784: 'a s', 785: 'lo', 786: 's of the ', 787: 'sa', 788: 'been', 789: '.”', 790: 'ves ', 791: 'ber', 792: 'ten ', 793: 'ready ', 794: 'ke', 795: 'med', 796: 'ast ', 797: 'cap', 798: 'chang', 799: 'ari', 800: 'ed in ', 801: 'even ', 802: 'ting ', 803: 'und', 804: 'ques', 805: 'mu', 806: 'alysis ', 807: 'I am ', 808: 'show', 809: 'in this ', 810: 'tis', 811: 'too', 812: 'differen', 813: 'here ', 814: ', however', 815: 'charac', 816: 'had', 817: 'opp', 818: ' she ', 819: ' any ', 820: 'e that ', 821: 'produc', 822: 'fre', 823: 'which are ', 824: ' as a ', 825: 'ight', 826: 'ogn', 827: 'secon', 828: 'tat', 829: 'place ', 830: 'inv', 831: 'llec', 832: ', and the ', 833: ' also ', 834: 'life ', 835: '.[', 836: 'hy', 837: 've', 838: 'take ', 839: ' thought ', 840: 'origin', 841: '(p. ', 842: 'la', 843: 'ps ', 844: 'tain ', 845: 'found ', 846: ' those ', 847: 'anc', 848: 'ations', 849: 'lear', 850: 'tion of the ', 851: 'many ', 852: '. It is ', 853: '. On', 854: 'just', 855: 'pur', 856: 'contin', 857: 'poin', 858: 'becom', 859: 'serv', 860: 'nific', 861: 'does not ', 862: 'I sh', 863: 'call', 864: 'fi', 865: 'th ', 866: 'ties ', 867: 'ings ', 868: '.\\nThe ', 869: ' appear', 870: 'explan', 871: ' thoughts', 872: 'ing, ', 873: ', that ', 874: '; the ', 875: '? ', 876: 'king ', 877: ' as the ', 878: '. He ', 879: 'bro', 880: 'm ', 881: 'val', 882: 'though', 883: 'ack ', 884: 'comm', 885: 'recogn', 886: 'manif', 887: ' the same ', 888: 'vis', 889: 'ance', 890: 'ult', 891: 'impression', 892: 'subjec', 893: 'ow ', 894: 'every ', 895: 'during the ', 896: 'hi', 897: 'man ', 898: 'sc', 899: 'vel', 900: 'til', 901: 'condi', 902: 'ass', 903: 'soci', 904: 'cens', 905: 'den', 906: 'he', 907: 'itself ', 908: 'own', 909: 'tion of ', 910: 'direc', 911: 'gu', 912: ' thin', 913: 'unc', 914: 'termin', 915: 'posi', 916: 'become ', 917: 'life', 918: 'pictu', 919: 'est', 920: 'psycholog', 921: ',” ', 922: 'ey', 923: 'find', 924: 'mis', 925: 'in s', 926: 'remain', 927: 'org', 928: 'out the ', 929: 'ation, ', 930: 'ems ', 931: 'percep', 932: 'possible ', 933: ', a ', 934: 'hoo', 935: 'inde', 936: 't to ', 937: 'old ', 938: ' sub', 939: 'patient', 940: '.”\\n', 941: ' thus ', 942: 'I was ', 943: ' and the ', 944: 'ong ', 945: 'respon', 946: 'dea', 947: 'press', 948: 'omething ', 949: 'men', 950: 'num', 951: 'sens', 952: 'we are ', 953: 'interpretation ', 954: 'cannot ', 955: 'tow', 956: 'concer', 957: 'emo', 958: 'exual ', 959: 'I had ', 960: 'up ', 961: 'pain', 962: 'waken', 963: '..', 964: 'cus', 965: 'dec', 966: 'ks ', 967: 'y the ', 968: ', wh', 969: 'is a ', 970: 'unconscious ', 971: 'trac', 972: 'lea', 973: ' them ', 974: 'case ', 975: ' activity ', 976: 'dem', 977: 'id ', 978: 'thor', 979: 'imp', 980: 'wish-', 981: 'flu', 982: 'youn', 983: 'of my ', 984: 'ish ', 985: 'struc', 986: 'taken ', 987: 'timuli', 988: ' after', 989: 'continu', 990: 'young', 991: '(_', 992: 'ness', 993: 'make ', 994: 'vers', 995: 'tri', 996: 'person ', 997: 'friend ', 998: 'fu', 999: 'ie', 1000: 'less ', 1001: 'might ', 1002: 's and ', 1003: 'once ', 1004: 'often ', 1005: 'is, ', 1006: 'ently ', 1007: 'without ', 1008: 'prob', 1009: 'old', 1010: 'occa', 1011: 'memor', 1012: 'process', 1013: 'because ', 1014: 'purpos', 1015: 'mind', 1016: 'being ', 1017: 'word', 1018: ' again', 1019: 'consider', 1020: 's, and ', 1021: 'vid', 1022: 'reas', 1023: 'ely', 1024: 'in which ', 1025: 'resul', 1026: 'comp', 1027: ' about ', 1028: 'diffic', 1029: 'great ', 1030: ', however, ', 1031: 'cr'}, token_to_idx={'\\n': 0, ' ': 1, '!': 2, '&': 3, '(': 4, ')': 5, ',': 6, '-': 7, '.': 8, '0': 9, '1': 10, '2': 11, '3': 12, '4': 13, '5': 14, '6': 15, '7': 16, '8': 17, '9': 18, ':': 19, ';': 20, '=': 21, '?': 22, 'A': 23, 'B': 24, 'C': 25, 'D': 26, 'E': 27, 'F': 28, 'G': 29, 'H': 30, 'I': 31, 'J': 32, 'K': 33, 'L': 34, 'M': 35, 'N': 36, 'O': 37, 'P': 38, 'Q': 39, 'R': 40, 'S': 41, 'T': 42, 'U': 43, 'V': 44, 'W': 45, 'X': 46, 'Y': 47, 'Z': 48, '[': 49, ']': 50, '_': 51, 'a': 52, 'b': 53, 'c': 54, 'd': 55, 'e': 56, 'f': 57, 'g': 58, 'h': 59, 'i': 60, 'j': 61, 'k': 62, 'l': 63, 'm': 64, 'n': 65, 'o': 66, 'p': 67, 'q': 68, 'r': 69, 's': 70, 't': 71, 'u': 72, 'v': 73, 'w': 74, 'x': 75, 'y': 76, 'z': 77, '·': 78, 'À': 79, 'Â': 80, 'Æ': 81, 'É': 82, 'Ü': 83, 'à': 84, 'ä': 85, 'æ': 86, 'ç': 87, 'è': 88, 'é': 89, 'ê': 90, 'î': 91, 'ï': 92, 'ó': 93, 'ô': 94, 'û': 95, 'ü': 96, 'Œ': 97, 'œ': 98, '̓': 99, 'Ψ': 100, 'έ': 101, 'ν': 102, 'ς': 103, 'υ': 104, 'χ': 105, '–': 106, '—': 107, '‘': 108, '’': 109, '“': 110, '”': 111, 'e ': 112, 'th': 113, ' th': 114, 's ': 115, 'in': 116, 're': 117, ' the ': 118, 'on': 119, ' a': 120, 'er': 121, 't ': 122, 'd ': 123, 'en': 124, 'of': 125, 'ti': 126, 'y ': 127, 'or': 128, 'to': 129, ', ': 130, 'an': 131, 'ou': 132, 'rea': 133, 'ch': 134, '. ': 135, 'is ': 136, 'ing': 137, 'tion': 138, 'al': 139, 'ar': 140, 'wh': 141, 'ream': 142, 'dream': 143, 'is': 144, ' s': 145, ' an': 146, 'at': 147, 'es': 148, 'ed ': 149, 'of ': 150, 'om': 151, 'it': 152, 'ha': 153, 'to ': 154, 'er ': 155, 'con': 156, 'of the ': 157, 'el': 158, 'whi': 159, 'ation': 160, 'ing ': 161, 'which': 162, 'for': 163, 'no': 164, 'es ': 165, 'ed': 166, 'ec': 167, ' a ': 168, 'he ': 169, 'si': 170, 'in ': 171, 'em': 172, 'ur': 173, 'st': 174, 'ic': 175, 'ly ': 176, 'ent': 177, ' and ': 178, 'ex': 179, 'gh': 180, 'at ': 181, 've ': 182, 'res': 183, 'wi': 184, 'in the ': 185, 'dream ': 186, 'which ': 187, 'ac': 188, 'll': 189, 'le ': 190, 'wa': 191, 'I ': 192, 'ow': 193, 'en ': 194, 'ul': 195, 'us': 196, 'os': 197, 'un': 198, 'im': 199, 'o ': 200, 'be': 201, 'al ': 202, 'with': 203, 'pl': 204, 'fr': 205, 'as': 206, 'it ': 207, 'ro': 208, 'ma': 209, 'e th': 210, ' that ': 211, 'ation ': 212, '. T': 213, ' this ': 214, 'ough': 215, 'if': 216, 'ver': 217, 'tr': 218, 'ir': 219, 'de': 220, 'on ': 221, 'il': 222, 'pres': 223, 'ter': 224, 'a ': 225, 'ent ': 226, 'be ': 227, 'le': 228, 'per': 229, 'ta': 230, 'our': 231, 'have ': 232, 'tion ': 233, 'ce ': 234, 'to the ': 235, 'from': 236, ', and ': 237, 'oth': 238, 'ish': 239, 'am': 240, 'not ': 241, ' as ': 242, 'su': 243, 'pro': 244, 'ol': 245, 'ere': 246, 'com': 247, 'we ': 248, 'ab': 249, 'sy': 250, 'ci': 251, 'all': 252, 'dis': 253, 'his ': 254, 'ce': 255, 'my ': 256, 'an ': 257, 'se': 258, 'has ': 259, '.\\n': 260, 'qu': 261, ' that': 262, '. I': 263, ' and': 264, 'pp': 265, '. The ': 266, 'one ': 267, 'ts ': 268, 'was ': 269, 'ere ': 270, 'ear': 271, 'or ': 272, 'bu': 273, ' ar': 274, 'up': 275, 'me': 276, 'sych': 277, ' though': 278, 'li': 279, 'rec': 280, 'n ': 281, 'oun': 282, 'by ': 283, 'cc': 284, 's, ': 285, 'psych': 286, 'ri': 287, ' the': 288, 'par': 289, 'di': 290, 'e the ': 291, 'and ': 292, 'sel': 293, 'ly': 294, 'tic': 295, '; ': 296, 'by': 297, 'us ': 298, 'pa': 299, '” ': 300, 'pre': 301, 'with ': 302, 'had ': 303, ' as': 304, 'oul': 305, 'ne': 306, 'ted ': 307, 'for ': 308, 'ag': 309, 'ess': 310, 'cont': 311, 'now': 312, 'cons': 313, 't the ': 314, 'wish': 315, 'tim': 316, 'ens': 317, 'll ': 318, 'ob': 319, 'and': 320, 'id': 321, 'k ': 322, 'its ': 323, 'ould ': 324, 'ad': 325, 'man': 326, 'other ': 327, 'how': 328, ' are ': 329, 'tu': 330, 'tw': 331, 'self': 332, ', the ': 333, ', and': 334, 'ous ': 335, 'ay': 336, 'ong': 337, 'form': 338, 'ep': 339, 'ind': 340, 'are ': 341, 'der': 342, 'ity ': 343, 'ful': 344, 'uc': 345, 'ess ': 346, 'fo': 347, 'ten': 348, ' ac': 349, 'our ': 350, 'psychic': 351, 'ig': 352, ' su': 353, 'og': 354, 'ph': 355, 'ous': 356, ' an ': 357, 'ke ': 358, 'wor': 359, 'sion': 360, ' the s': 361, 'ra': 362, 'may ': 363, 'et': 364, 'been ': 365, 'e, ': 366, 'pos': 367, 'inter': 368, 'mor': 369, 'ame ': 370, 'him': 371, 'consci': 372, 'jec': 373, 'po': 374, ': ': 375, 'present': 376, 'sion ': 377, 'from ': 378, 'ev': 379, 'ch ': 380, 'bec': 381, 'ell': 382, 'ien': 383, 'ter ': 384, ' al': 385, 'of the dream': 386, 'ever': 387, 'on the ': 388, 'e of ': 389, 'mo': 390, 'as ': 391, 'igh': 392, 'ing the ': 393, 'cl': 394, '. A': 395, 'able ': 396, 'ain': 397, 'ations ': 398, 'for the ': 399, 'dreams ': 400, 'but ': 401, 'fac': 402, 'other': 403, ' that the ': 404, 'ther': 405, 'of a ': 406, 'ea': 407, 'um': 408, 'who ': 409, 'from the ': 410, 'co': 411, 'fa': 412, 'vi': 413, 'occ': 414, 'ther ': 415, 'chil': 416, 'ate ': 417, 'eri': 418, 'so ': 419, 'ally ': 420, 'fir': 421, 'her ': 422, 'ble ': 423, 'fere': 424, 'to be ': 425, 'by the ': 426, 'mat': 427, 'bo': 428, 'ome ': 429, 'ment': 430, 'to s': 431, 'ust ': 432, 'pr': 433, 'wak': 434, 'nec': 435, ' at': 436, 'plac': 437, 'out ': 438, 'The ': 439, ' a s': 440, 'ory ': 441, 'ese ': 442, 'y, ': 443, 'in the dream': 444, 'so': 445, 'bl': 446, 'fe': 447, 'int': 448, 'ca': 449, 'tiv': 450, 'of the dream ': 451, 'str': 452, 'interpre': 453, 'me ': 454, '’s ': 455, 'pec': 456, 's the ': 457, 's of ': 458, 'ren': 459, ' am': 460, 'feren': 461, 'rel': 462, 'pers': 463, 'ang': 464, 'rough': 465, 'tur': 466, 'ing s': 467, 'with the ': 468, 'sh': 469, 'red ': 470, ' ab': 471, 'do': 472, 'know': 473, 'leep': 474, '. W': 475, 'psychic ': 476, 'iv': 477, 'ff': 478, 'only ': 479, 'ost ': 480, 'Bu': 481, 'st ': 482, 'de ': 483, 'aly': 484, 'ar ': 485, 'cer': 486, 'ance ': 487, 'lif': 488, 'mem': 489, 'it is ': 490, 'ose ': 491, 'tak': 492, ' these ': 493, 'ord': 494, 'child': 495, 'interpret': 496, 'op': 497, 'llow': 498, ', which ': 499, ' them': 500, 'ir ': 501, 'must ': 502, 'ement': 503, 'of this ': 504, 'no ': 505, 'cas': 506, 'more ': 507, 'mean': 508, 'ment ': 509, 'self ': 510, 'ser': 511, 'des': 512, 'min': 513, ': “': 514, 'most ': 515, 'connec': 516, '. I ': 517, '. Th': 518, 'dif': 519, '_ ': 520, ' app': 521, 'tive ': 522, 'tions ': 523, 'oo': 524, 'w ': 525, 'would ': 526, 'expl': 527, '. It ': 528, 'ard': 529, 'can ': 530, 'fl': 531, 'all ': 532, 'cit': 533, 'alys': 534, 'lit': 535, 'thing ': 536, '. H': 537, 'materi': 538, 'et ': 539, 'of s': 540, 'ant': 541, 'ed to ': 542, '] ': 543, 'her': 544, 'enti': 545, '.” ': 546, ' thought': 547, 'ust': 548, 'follow': 549, 'first ': 550, 'ted': 551, 'very ': 552, 'fic': 553, 'read': 554, 'expres': 555, 'ay ': 556, ' at ': 557, 'fact': 558, 'ite ': 559, ', as ': 560, 'lat': 561, ' sh': 562, 'cep': 563, 'represent': 564, 'dur': 565, ' all': 566, 'two ': 567, 'ence ': 568, ' their ': 569, '. Bu': 570, 'ans': 571, ' there ': 572, 'por': 573, 'au': 574, 'ide': 575, ' the dream ': 576, 't of ': 577, 'exam': 578, 'over': 579, 'year': 580, 'es, ': 581, 'compl': 582, 'tain': 583, 'f ': 584, 'pe': 585, 'the ': 586, 'ical ': 587, ' of ': 588, 'gr': 589, 'I have ': 590, 'cor': 591, 'ome': 592, 'my': 593, 'who': 594, ' thoughts ': 595, ' through': 596, 'what ': 597, 'in the dream ': 598, 'fur': 599, 'ill': 600, 'ure ': 601, 'olog': 602, 'not': 603, 'occur': 604, 'ary ': 605, 'ated ': 606, 'conscious': 607, ' they ': 608, ' se': 609, 'content': 610, 'timul': 611, 'person': 612, ' af': 613, ' ag': 614, 'pati': 615, 'tic ': 616, 'under': 617, 'es the ': 618, 'day': 619, 'reg': 620, 'proc': 621, 'ud': 622, 'way': 623, 'bel': 624, 'she ': 625, 'exper': 626, 'conscious ': 627, 'duc': 628, 'ual ': 629, 'ant ': 630, 'pic': 631, ', but ': 632, 'frien': 633, 'ation of ': 634, 'fulf': 635, 'fin': 636, 'pu': 637, ' acc': 638, 'will ': 639, 'ound ': 640, 'go': 641, 'ement ': 642, 'impres': 643, 'sible ': 644, 'wish ': 645, 'can': 646, 'ness ': 647, 'char': 648, 'ity': 649, 'part ': 650, 'I am': 651, 'ces ': 652, 'tle ': 653, 'were ': 654, 's to ': 655, 'out': 656, '. O': 657, 'ed by ': 658, 'own ': 659, 'ed the ': 660, 'sub': 661, 'contr': 662, 'se ': 663, 'you': 664, ') ': 665, 'end': 666, ' ad': 667, 'real': 668, 'which is ': 669, 'long': 670, 'sti': 671, ' at the ': 672, 'est ': 673, 'ely ': 674, 'app': 675, 'grea': 676, 'ure': 677, 'but': 678, 'en the ': 679, 'trans': 680, 'experien': 681, 'cour': 682, 'cri': 683, 'gen': 684, 'p. ': 685, 'in a ': 686, 'into the ': 687, 'to a ': 688, 'use ': 689, 'ist': 690, '. In': 691, 'we have ': 692, 'now ': 693, 'time ': 694, 'however': 695, 'nif': 696, 'orig': 697, '. F': 698, 'which the ': 699, 'fore': 700, 'ffec': 701, 'ise ': 702, 'ive ': 703, 'pon': 704, 'is the ': 705, 'twe': 706, 'do ': 707, 'betwe': 708, 'content ': 709, 'dreams': 710, 'objec': 711, 'tly ': 712, '. S': 713, 'ed, ': 714, 'does ': 715, 'ain ': 716, 'ner': 717, 'one': 718, 'fore ': 719, 'dist': 720, '. We ': 721, 'ge ': 722, 'es of ': 723, 'ight ': 724, 'mp': 725, 'at the ': 726, '. This ': 727, 'ing to ': 728, 'excit': 729, 'al s': 730, 'om ': 731, ' activ': 732, 'into ': 733, 'only': 734, 'while ': 735, 'ation of the ': 736, 'sur': 737, '.\\nI': 738, 'red': 739, 'little ': 740, 'mar': 741, 'ge': 742, 'same ': 743, 'ue ': 744, 'if ': 745, 'beca': 746, 'consi': 747, 'ful ': 748, 'feel': 749, 'trea': 750, '._': 751, 'inc': 752, 'em ': 753, 'has been ': 754, 'him ': 755, 'eas': 756, 'way ': 757, 'ound': 758, '. But ': 759, 'sig': 760, 'giv': 761, 'nat': 762, 'ver ': 763, ' there': 764, 'emp': 765, 'made ': 766, 'upon ': 767, 'material ': 768, 'fulfil': 769, 'day ': 770, 'element': 771, 'fer': 772, 'when ': 773, ' another ': 774, 'br': 775, ' all ': 776, '. M': 777, 'ed by the ': 778, 'like ': 779, 'well': 780, 'd of ': 781, 'main': 782, 'may be ': 783, 'a s': 784, 'lo': 785, 's of the ': 786, 'sa': 787, 'been': 788, '.”': 789, 'ves ': 790, 'ber': 791, 'ten ': 792, 'ready ': 793, 'ke': 794, 'med': 795, 'ast ': 796, 'cap': 797, 'chang': 798, 'ari': 799, 'ed in ': 800, 'even ': 801, 'ting ': 802, 'und': 803, 'ques': 804, 'mu': 805, 'alysis ': 806, 'I am ': 807, 'show': 808, 'in this ': 809, 'tis': 810, 'too': 811, 'differen': 812, 'here ': 813, ', however': 814, 'charac': 815, 'had': 816, 'opp': 817, ' she ': 818, ' any ': 819, 'e that ': 820, 'produc': 821, 'fre': 822, 'which are ': 823, ' as a ': 824, 'ight': 825, 'ogn': 826, 'secon': 827, 'tat': 828, 'place ': 829, 'inv': 830, 'llec': 831, ', and the ': 832, ' also ': 833, 'life ': 834, '.[': 835, 'hy': 836, 've': 837, 'take ': 838, ' thought ': 839, 'origin': 840, '(p. ': 841, 'la': 842, 'ps ': 843, 'tain ': 844, 'found ': 845, ' those ': 846, 'anc': 847, 'ations': 848, 'lear': 849, 'tion of the ': 850, 'many ': 851, '. It is ': 852, '. On': 853, 'just': 854, 'pur': 855, 'contin': 856, 'poin': 857, 'becom': 858, 'serv': 859, 'nific': 860, 'does not ': 861, 'I sh': 862, 'call': 863, 'fi': 864, 'th ': 865, 'ties ': 866, 'ings ': 867, '.\\nThe ': 868, ' appear': 869, 'explan': 870, ' thoughts': 871, 'ing, ': 872, ', that ': 873, '; the ': 874, '? ': 875, 'king ': 876, ' as the ': 877, '. He ': 878, 'bro': 879, 'm ': 880, 'val': 881, 'though': 882, 'ack ': 883, 'comm': 884, 'recogn': 885, 'manif': 886, ' the same ': 887, 'vis': 888, 'ance': 889, 'ult': 890, 'impression': 891, 'subjec': 892, 'ow ': 893, 'every ': 894, 'during the ': 895, 'hi': 896, 'man ': 897, 'sc': 898, 'vel': 899, 'til': 900, 'condi': 901, 'ass': 902, 'soci': 903, 'cens': 904, 'den': 905, 'he': 906, 'itself ': 907, 'own': 908, 'tion of ': 909, 'direc': 910, 'gu': 911, ' thin': 912, 'unc': 913, 'termin': 914, 'posi': 915, 'become ': 916, 'life': 917, 'pictu': 918, 'est': 919, 'psycholog': 920, ',” ': 921, 'ey': 922, 'find': 923, 'mis': 924, 'in s': 925, 'remain': 926, 'org': 927, 'out the ': 928, 'ation, ': 929, 'ems ': 930, 'percep': 931, 'possible ': 932, ', a ': 933, 'hoo': 934, 'inde': 935, 't to ': 936, 'old ': 937, ' sub': 938, 'patient': 939, '.”\\n': 940, ' thus ': 941, 'I was ': 942, ' and the ': 943, 'ong ': 944, 'respon': 945, 'dea': 946, 'press': 947, 'omething ': 948, 'men': 949, 'num': 950, 'sens': 951, 'we are ': 952, 'interpretation ': 953, 'cannot ': 954, 'tow': 955, 'concer': 956, 'emo': 957, 'exual ': 958, 'I had ': 959, 'up ': 960, 'pain': 961, 'waken': 962, '..': 963, 'cus': 964, 'dec': 965, 'ks ': 966, 'y the ': 967, ', wh': 968, 'is a ': 969, 'unconscious ': 970, 'trac': 971, 'lea': 972, ' them ': 973, 'case ': 974, ' activity ': 975, 'dem': 976, 'id ': 977, 'thor': 978, 'imp': 979, 'wish-': 980, 'flu': 981, 'youn': 982, 'of my ': 983, 'ish ': 984, 'struc': 985, 'taken ': 986, 'timuli': 987, ' after': 988, 'continu': 989, 'young': 990, '(_': 991, 'ness': 992, 'make ': 993, 'vers': 994, 'tri': 995, 'person ': 996, 'friend ': 997, 'fu': 998, 'ie': 999, 'less ': 1000, 'might ': 1001, 's and ': 1002, 'once ': 1003, 'often ': 1004, 'is, ': 1005, 'ently ': 1006, 'without ': 1007, 'prob': 1008, 'old': 1009, 'occa': 1010, 'memor': 1011, 'process': 1012, 'because ': 1013, 'purpos': 1014, 'mind': 1015, 'being ': 1016, 'word': 1017, ' again': 1018, 'consider': 1019, 's, and ': 1020, 'vid': 1021, 'reas': 1022, 'ely': 1023, 'in which ': 1024, 'resul': 1025, 'comp': 1026, ' about ': 1027, 'diffic': 1028, 'great ': 1029, ', however, ': 1030, 'cr': 1031})\n",
      "1032\n"
     ]
    }
   ],
   "source": [
    "from utilities import text_cleaning\n",
    "from utilities import tokenizer2 as tokenizer\n",
    "text = text_cleaning.basic_cleaning(raw_text)\n",
    "td = tokenizer.create_tokenizer(text, num_tokens=1032)\n",
    "#td = tokenizer.reduce_token_dictionary(td, text)\n",
    "print(td)\n",
    "print(len(td.token_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c761734",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters, idx_to_token, token_to_idx = td\n",
    "encode = tokenizer.get_encoder(td)\n",
    "decode = tokenizer.get_decoder(td)\n",
    "data = torch.tensor(encode(text), dtype=torch.long).to(device=device)\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "block_size, batch_size = config.block_size, config.batch_size\n",
    "def get_batch(split):\n",
    "  data = train_data if split == 'train' else val_data\n",
    "  idxs = torch.randint(len(data) - block_size, (batch_size,))\n",
    "  x = torch.stack([data[i:i+block_size] for i in idxs])\n",
    "  y = torch.stack([data[i+1:i+block_size+1] for i in idxs])\n",
    "  return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_val_loss(model):\n",
    "  model.eval()\n",
    "  X, Y = get_batch(\"val\")\n",
    "  X = X.to(device=device)\n",
    "  Y = Y.to(device=device)\n",
    "  _, loss = model(X, Y)\n",
    "  model.train()\n",
    "  return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ee3ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gptv1.LanguageModel(len(characters), config).to(device)\n",
    "m.compile()\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=3e-4)\n",
    "import time\n",
    "from torch.amp import autocast\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ce7273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:52<00:00,  5.79it/s, train 2.807577610015869 val 6.2016496658325195]\n"
     ]
    }
   ],
   "source": [
    "val_loss = -1\n",
    "pbar = range(1000)\n",
    "for steps in pbar:\n",
    "\txb, yb = get_batch('train')\n",
    "\txb = xb.to(device)\n",
    "\tyb = yb.to(device)\n",
    "\twith autocast(device_type=\"mps\", dtype=torch.float16):\n",
    "\t\tlogits, loss = m(xb, yb)\n",
    "\toptimizer.zero_grad(set_to_none=True)\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\tif steps % 50 == 0:\n",
    "\t\tval_loss = estimate_val_loss(m)\n",
    "\tpbar.postfix = f\"train {loss.item()} val {val_loss}\"\n",
    "\tpbar.update()\n",
    "\ttorch.mps.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "458156b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mind or ae so o e as that hein on amn at aes  or  subue he as a  of nocea mtae,  reasin her ogicppt cored roproly  ome lible erd  the dream d th  ae main ab her cinal raer the rint to suborto ces morown m and  thoughtbin, th  itthe m eaof lmeane e rthe h very h "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m idx = torch.tensor([encode(\u001b[33m\"\u001b[39m\u001b[33mThe mind \u001b[39m\u001b[33m\"\u001b[39m)], dtype=torch.long, device=device)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mThe mind \u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m\t\u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflush\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/apps/toy-gpt/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:59\u001b[39m, in \u001b[36m_wrap_generator.<locals>.generator_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     56\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     57\u001b[39m             \u001b[38;5;66;03m# Pass the last request to the generator and get its response\u001b[39;00m\n\u001b[32m     58\u001b[39m             \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m                 response = gen.send(request)\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# We let the exceptions raised above by the generator's `.throw` or\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# `.send` methods bubble up to our caller, except for StopIteration\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# The generator informed us that it is done: take whatever its\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# returned value (if any) was and indicate that we're done too\u001b[39;00m\n\u001b[32m     66\u001b[39m     \u001b[38;5;66;03m# by returning it (see docs for python's return-statement).\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/apps/toy-gpt/src/models/gptv1.py:140\u001b[39m, in \u001b[36mLanguageModel.generate\u001b[39m\u001b[34m(self, idx, max_new_tokens)\u001b[39m\n\u001b[32m    138\u001b[39m tok_embed = \u001b[38;5;28mself\u001b[39m.token_embedding_table(idx_cond)\n\u001b[32m    139\u001b[39m pos_embed = \u001b[38;5;28mself\u001b[39m.position_embedding_table(torch.arange(T, device=device))\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtok_embed\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_embed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.lm_head(x)\n\u001b[32m    143\u001b[39m logits = logits[:, -\u001b[32m1\u001b[39m, :]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/apps/toy-gpt/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/apps/toy-gpt/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/apps/toy-gpt/venv/lib/python3.11/site-packages/torch/nn/modules/container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/apps/toy-gpt/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/apps/toy-gpt/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/apps/toy-gpt/src/models/gptv1.py:94\u001b[39m, in \u001b[36mBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \tx = torch.add(x, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msa\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     95\u001b[39m \tx = torch.add(x, \u001b[38;5;28mself\u001b[39m.ffwd(\u001b[38;5;28mself\u001b[39m.ln2(x)))\n\u001b[32m     96\u001b[39m \t\u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/apps/toy-gpt/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/apps/toy-gpt/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/apps/toy-gpt/src/models/gptv1.py:61\u001b[39m, in \u001b[36mMultiHeadAttention.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \tout = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheads\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \tout = \u001b[38;5;28mself\u001b[39m.dropout(\u001b[38;5;28mself\u001b[39m.proj(out))\n\u001b[32m     63\u001b[39m \t\u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "idx = torch.tensor([encode(\"The mind \")], dtype=torch.long, device=device)\n",
    "print(\"The mind \", end=\"\", flush=True)\n",
    "for token in m.generate(idx, max_new_tokens=200):\n",
    "\tprint(decode([token.item()])[0], end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4c3b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.128176 M parameters\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34bfce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(m.state_dict(), \"gptv1_sample1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2233ae0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c299321",
   "metadata": {},
   "source": [
    "Nice — thanks for the concrete numbers. A training loss of **3.2** vs validation **5.7** is a large gap and tells a clear story: either **overfitting** or **train/validation distribution mismatch** (or both). Below I’ll explain the likely causes, give concrete diagnostics you can run *right now*, and list prioritized, actionable fixes you can try.\n",
    "\n",
    "---\n",
    "\n",
    "## Quick reality check (what these numbers mean)\n",
    "\n",
    "* Per-token perplexities:\n",
    "  train PPL = `exp(3.2) ≈ 24.5`\n",
    "  val PPL   = `exp(5.7) ≈ 298`\n",
    "* Big gap — model fits training tokens much better than validation tokens.\n",
    "\n",
    "**Important:** because you switched from a char model to a subword model, raw token losses are not directly comparable to previous char losses. You should normalize for token size when comparing (see below).\n",
    "\n",
    "---\n",
    "\n",
    "## Immediate diagnostics (run these now)\n",
    "\n",
    "1. **Tokenizer consistency**\n",
    "   Confirm the *same tokenizer/version/model* is used for training and validation tokenization. If train and val were tokenized differently, large gaps appear instantly.\n",
    "\n",
    "2. **Check for `<unk>` / OOV rate**\n",
    "   Compute fraction of tokens in validation that are unknown or mapped to an `<unk>` token. High OOV on val → huge loss.\n",
    "\n",
    "3. **Distribution mismatch**\n",
    "   Compare token frequency histograms between train and val (top-1k tokens, tail mass). Large differences = mismatch.\n",
    "\n",
    "4. **Average chars-per-token**\n",
    "   Compute `avg_chars_per_token = total_chars / total_tokens` on both splits. You’ll need this for normalized comparisons.\n",
    "\n",
    "5. **Per-token-length normalized loss**\n",
    "   Convert token loss to loss-per-character:\n",
    "\n",
    "   ```\n",
    "   loss_per_char = loss_per_token / avg_chars_per_token\n",
    "   ```\n",
    "\n",
    "   and then `char_ppl = exp(loss_per_char)`. This lets you compare to your old char model.\n",
    "\n",
    "6. **Overfit signs**\n",
    "   Check validation loss curve vs training loss curve. If train keeps dropping and val plateaus/rises → overfitting.\n",
    "\n",
    "7. **Batch/evaluation bug search**\n",
    "\n",
    "   * Ensure eval uses same masking/prefix/seq-len and that you're not accidentally including padding in loss (or not masking it).\n",
    "   * Ensure train uses teacher forcing same as eval.\n",
    "   * Re-tokenize a handful of validation examples and verify the tokens make sense.\n",
    "\n",
    "---\n",
    "\n",
    "## Likely causes (with how they tie to your numbers)\n",
    "\n",
    "1. **Huge vocabulary size → harder softmax**\n",
    "   Subword vocab of tens of thousands makes random-init predictions much worse and increases early loss. This influences both train and val but train can overfit.\n",
    "\n",
    "2. **Overfitting to subword idiosyncrasies**\n",
    "   BPE tokens can be rarer and more specific; model memorizes token combinations in train but fails to generalize.\n",
    "\n",
    "3. **Train/validation tokenization mismatch**\n",
    "   If e.g. training had leading spaces preserved and validation didn’t (or different normalization), the model’s predictions will be wrong on val.\n",
    "\n",
    "4. **High OOV / rare token mass in validation**\n",
    "   If validation contains many tokens or token sequences that were rare in training, loss will spike.\n",
    "\n",
    "5. **Regularization / capacity mismatch**\n",
    "   Your model may be too big for training data amount (or lacks dropout/weight decay), so train gets low loss and val stays high.\n",
    "\n",
    "6. **Optimization / learning rate issues**\n",
    "   Wrong LR schedule (too high or too low, or no warmup) can cause poor generalization.\n",
    "\n",
    "---\n",
    "\n",
    "## Concrete, prioritized fixes (try in this order)\n",
    "\n",
    "### Quick checks & fixes (cheap)\n",
    "\n",
    "1. **Verify tokenizer parity** (most common cause).\n",
    "2. **Report OOV%** — if >1–2% on val, shrink vocab or retrain tokenizer.\n",
    "3. **Ensure padding tokens are masked out during loss** in evaluation.\n",
    "\n",
    "### Strong, cheap experiments\n",
    "\n",
    "4. **Compute normalized (per-character) losses** so you know if val is truly worse or just different units. (See formulas below.)\n",
    "5. **Add / increase dropout** (e.g., 0.1 → 0.2 or 0.3) and/or **label smoothing** (0.05–0.1).\n",
    "6. **Add weight decay** (e.g., 0.01) if not used.\n",
    "\n",
    "### Medium-cost training changes\n",
    "\n",
    "7. **Reduce vocabulary** (e.g., 50k → 32k or 20k) and retrain tokenizer, then retrain model (or fine-tune). Smaller vocab reduces sparsity and makes softmax easier.\n",
    "8. **Use adaptive / sampled softmax** or **tied input/output embeddings** to stabilize training with large vocab.\n",
    "9. **Use data augmentation**: token dropout, span masking, simple noise to inputs to reduce memorization.\n",
    "\n",
    "### Stronger changes (if above fail)\n",
    "\n",
    "10. **More data** or better data mixing: increase train set size, or mix in similar-domain data so validation distribution is covered.\n",
    "11. **Regularization & early stopping** with validation checkpoints — stop before heavy overfitting.\n",
    "12. **Different tokenization strategy**: consider byte-level BPE or Unigram LM (SentencePiece), or smaller merges — sometimes gives more robust tokens than your current BPE.\n",
    "\n",
    "### Optimization schedule\n",
    "\n",
    "13. **AdamW**, warmup (e.g., 1–2k steps), then cosine or linear decay. Typical LR starting point: `1e-4` for medium models; tune. Use gradient clipping (1.0).\n",
    "\n",
    "---\n",
    "\n",
    "## Useful formulas / examples\n",
    "\n",
    "* token → char conversion:\n",
    "\n",
    "  ```\n",
    "  avg_chars_per_token = total_chars / total_tokens\n",
    "  loss_per_char = loss_per_token / avg_chars_per_token\n",
    "  char_ppl = exp(loss_per_char)\n",
    "  ```\n",
    "\n",
    "  Example: if `avg_chars_per_token = 4`:\n",
    "\n",
    "  * train loss_per_char = `3.2 / 4 = 0.8` → `char_ppl = exp(0.8) ≈ 2.23`\n",
    "  * val loss_per_char   = `5.7 / 4 = 1.425` → `char_ppl = exp(1.425) ≈ 4.16`\n",
    "\n",
    "  So your model might still be competitive per character even if token loss looks large — but the big gap suggests a generalization problem beyond just unit scaling.\n",
    "\n",
    "* perplexity: `PPL = exp(loss)` (token-level), or `exp(loss_per_char)` for char-level.\n",
    "\n",
    "---\n",
    "\n",
    "## Practical commands/snippets (pseudocode)\n",
    "\n",
    "1. Tokenizer parity & OOV:\n",
    "\n",
    "```python\n",
    "# assuming tokenizer.encode returns list of token ids, unk id = tokenizer.unk_id\n",
    "train_unk_rate = sum(id==unk for ids in train_tok for id in ids) / total_train_tokens\n",
    "val_unk_rate   = sum(id==unk for ids in val_tok   for id in ids) / total_val_tokens\n",
    "```\n",
    "\n",
    "2. Avg chars per token:\n",
    "\n",
    "```python\n",
    "avg_chars_per_token_train = sum(len(s) for s in train_texts) / sum(len(tok) for tok in train_token_lists)\n",
    "avg_chars_per_token_val   = ...\n",
    "```\n",
    "\n",
    "3. Per-token-frequency tail mass:\n",
    "\n",
    "```python\n",
    "from collections import Counter\n",
    "c = Counter(t for ids in train_token_lists for t in ids)\n",
    "# compare top-k frequencies to validation\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## How to tell if it’s *only* a tokenization unit issue vs generalization\n",
    "\n",
    "* If **loss_per_char** gap is small (train ≈ val after normalization) → mostly unit/granularity effect.\n",
    "* If **loss_per_char** still shows big gap → real generalization / data mismatch / overfitting problem.\n",
    "\n",
    "---\n",
    "\n",
    "## Final short checklist you can run now\n",
    "\n",
    "1. Confirm same tokenizer used for both splits.\n",
    "2. Compute `val_unk_rate`.\n",
    "3. Compute `avg_chars_per_token` and `loss_per_char` for train/val.\n",
    "4. Plot token-frequency histograms for train vs val (top 5k tokens).\n",
    "5. Try increasing dropout to 0.2 and add weight decay 0.01; retrain a few epochs and watch val.\n",
    "6. If OOV high or distribution mismatch persists → reduce vocab (32k) or switch to byte-level.\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can:\n",
    "\n",
    "* show a quick small script to compute `avg_chars_per_token`, `loss_per_char`, and OOV rate on your datasets (paste the tokenized counts or a small sample), **or**\n",
    "* recommend specific hyperparameter values for your model size (tell me model size / vocab size / training steps), and I’ll give a tuned recipe.\n",
    "\n",
    "Which of those would be most useful right now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89447c65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
