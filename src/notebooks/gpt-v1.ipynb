{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a932b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from models import gptv1\n",
    "\n",
    "config = gptv1.GPTv1Config(device = \"mps\", batch_size = 16, block_size=256, n_heads=6)\n",
    "device = config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3635c630",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../../data/freud/interpretation-of-dreams.txt\"\n",
    "input_file = open(filepath, 'r', encoding='utf-8')\n",
    "raw_text = input_file.read()\n",
    "input_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "798b822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "cleaned_text = raw_text.replace('\\ufeff', '')\n",
    "cleaned_text = re.sub(r'^[ \\t]+|[ \\t]+$', '', cleaned_text, flags=re.MULTILINE)\n",
    "cleaned_text = re.sub(r'\\n{2,}', '\\n\\n', cleaned_text)\n",
    "cleaned_text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', cleaned_text)\n",
    "cleaned_text = re.sub(r' {2,}', ' ', cleaned_text)\n",
    "cleaned_text = re.sub(r'\\n\\n', '\\n', cleaned_text)\n",
    "text = cleaned_text.strip()\n",
    "characters = sorted(list(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c761734",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_token = dict(enumerate(characters))\n",
    "token_to_idx = {t: i for i, t in enumerate(characters)}\n",
    "encode = lambda s: list(map(token_to_idx.__getitem__, s))\n",
    "decode = lambda s: list(map(idx_to_token.__getitem__, s))\n",
    "data = torch.tensor(encode(text), dtype=torch.long).to(device=device)\n",
    "\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "block_size, batch_size = config.block_size, config.batch_size\n",
    "def get_batch(split):\n",
    "  data = train_data if split == 'train' else val_data\n",
    "  idxs = torch.randint(len(data) - block_size, (batch_size,))\n",
    "  x = torch.stack([data[i:i+block_size] for i in idxs])\n",
    "  y = torch.stack([data[i+1:i+block_size+1] for i in idxs])\n",
    "  return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_val_loss(model):\n",
    "  model.eval()\n",
    "  X, Y = get_batch(\"val\")\n",
    "  X = X.to(device=device)\n",
    "  Y = Y.to(device=device)\n",
    "  _, loss = model(X, Y)\n",
    "  model.train()\n",
    "  return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36aa9275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cudagraphs', 'inductor', 'onnxrt', 'openxla', 'tvm']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch._dynamo.list_backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7ee3ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gptv1.LanguageModel(len(characters), config).to(device)\n",
    "# m.compile()\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=3e-4)\n",
    "import time\n",
    "from torch.amp import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21ce7273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 1.1247825622558594 | val: 0.9980862736701965\n",
      "100: 1.0756864547729492 | val: 1.0950121879577637\n",
      "200: 1.0799243450164795 | val: 1.1442018747329712\n",
      "300: 1.111983299255371 | val: 1.1099348068237305\n",
      "400: 1.1372044086456299 | val: 1.0408183336257935\n",
      "500: 1.0872889757156372 | val: 1.0317912101745605\n",
      "600: 1.1487681865692139 | val: 1.11277174949646\n",
      "700: 1.0998644828796387 | val: 1.0333386659622192\n",
      "800: 1.07499098777771 | val: 1.0962469577789307\n",
      "900: 1.1547526121139526 | val: 1.0294935703277588\n"
     ]
    }
   ],
   "source": [
    "for steps in range(1000):\n",
    "\txb, yb = get_batch('train')\n",
    "\txb = xb.to(device)\n",
    "\tyb = yb.to(device)\n",
    "\twith autocast(device_type=\"mps\", dtype=torch.float16):\n",
    "\t\tlogits, loss = m(xb, yb)\n",
    "\toptimizer.zero_grad(set_to_none=True)\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\tif steps % 100 == 0:\n",
    "\t\tval_loss = estimate_val_loss(m)\n",
    "\t\tprint(f\"{steps}: {loss.item()} | val: {val_loss}\")\n",
    "\ttorch.mps.synchronize()\n",
    "\ttime.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "458156b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Richard devoured eight can we sati, by the dream which are knew with other, because with ones or universal comprehensity.\n",
      "But the dreamer must as later difference the best; I expel his contains the presence o\n"
     ]
    }
   ],
   "source": [
    "idx = torch.tensor([encode(\"Richard \")], dtype=torch.long, device=device)\n",
    "print(\"Richard \", end=\"\", flush=True)\n",
    "for token in m.generate_stream(idx, max_new_tokens=200):\n",
    "\tprint(decode([token.item()])[0], end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be4c3b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.128176 M parameters\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a34bfce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(m.state_dict(), \"gptv1_sample1.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
