{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a932b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from models import gptv1\n",
    "\n",
    "config = gptv1.GPTv1Config(device = \"mps\", batch_size = 16, block_size=256, n_heads=6)\n",
    "device = config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3635c630",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../../data/freud/interpretation-of-dreams.txt\"\n",
    "input_file = open(filepath, 'r', encoding='utf-8')\n",
    "raw_text = input_file.read()\n",
    "input_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "798b822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "cleaned_text = raw_text.replace('\\ufeff', '')\n",
    "cleaned_text = re.sub(r'^[ \\t]+|[ \\t]+$', '', cleaned_text, flags=re.MULTILINE)\n",
    "cleaned_text = re.sub(r'\\n{2,}', '\\n\\n', cleaned_text)\n",
    "cleaned_text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', cleaned_text)\n",
    "cleaned_text = re.sub(r' {2,}', ' ', cleaned_text)\n",
    "cleaned_text = re.sub(r'\\n\\n', '\\n', cleaned_text)\n",
    "text = cleaned_text.strip()\n",
    "characters = sorted(list(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c761734",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_token = dict(enumerate(characters))\n",
    "token_to_idx = {t: i for i, t in enumerate(characters)}\n",
    "encode = lambda s: list(map(token_to_idx.__getitem__, s))\n",
    "decode = lambda s: list(map(idx_to_token.__getitem__, s))\n",
    "data = torch.tensor(encode(text), dtype=torch.long).to(device=device)\n",
    "\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "block_size, batch_size = config.block_size, config.batch_size\n",
    "def get_batch(split):\n",
    "  data = train_data if split == 'train' else val_data\n",
    "  idxs = torch.randint(len(data) - block_size, (batch_size,))\n",
    "  x = torch.stack([data[i:i+block_size] for i in idxs])\n",
    "  y = torch.stack([data[i+1:i+block_size+1] for i in idxs])\n",
    "  return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_val_loss(model):\n",
    "  model.eval()\n",
    "  X, Y = get_batch(\"val\")\n",
    "  X = X.to(device=device)\n",
    "  Y = Y.to(device=device)\n",
    "  _, loss = model(X, Y)\n",
    "  model.train()\n",
    "  return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ee3ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gptv1.LanguageModel(len(characters), config).to(device)\n",
    "m.compile()\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=3e-4)\n",
    "import time\n",
    "from torch.amp import autocast\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21ce7273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:29<00:00,  6.69it/s, train 1.0835226774215698 val 1.0783356428146362]\n"
     ]
    }
   ],
   "source": [
    "val_loss = -1\n",
    "pbar = tqdm(range(1000))\n",
    "for steps in pbar:\n",
    "\txb, yb = get_batch('train')\n",
    "\txb = xb.to(device)\n",
    "\tyb = yb.to(device)\n",
    "\twith autocast(device_type=\"mps\", dtype=torch.float16):\n",
    "\t\tlogits, loss = m(xb, yb)\n",
    "\toptimizer.zero_grad(set_to_none=True)\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\tif steps % 50 == 0:\n",
    "\t\tval_loss = estimate_val_loss(m)\n",
    "\tpbar.postfix = f\"train {loss.item()} val {val_loss}\"\n",
    "\tpbar.update()\n",
    "\ttorch.mps.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458156b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mind is permissively to amplicate thoughts and conclusive for the experisting in the dream picture, which is question of sleep, every tablishness to asuming from an ansanect is a very percoal; and one only\n"
     ]
    }
   ],
   "source": [
    "idx = torch.tensor([encode(\"The mind \")], dtype=torch.long, device=device)\n",
    "print(\"The mind \", end=\"\", flush=True)\n",
    "for token in m.generate(idx, max_new_tokens=200):\n",
    "\tprint(decode([token.item()])[0], end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be4c3b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.128176 M parameters\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34bfce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(m.state_dict(), \"gptv1_sample1.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
