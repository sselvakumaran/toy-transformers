{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a932b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from models import gptv1\n",
    "\n",
    "config = gptv1.GPTv1Config(device=\"mps\", batch_size=16, block_size=256, n_heads=6)\n",
    "device = config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3635c630",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../../data/freud/interpretation-of-dreams.txt\"\n",
    "input_file = open(filepath, 'r', encoding='utf-8')\n",
    "raw_text = input_file.read()\n",
    "input_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798b822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import text_cleaning\n",
    "text = text_cleaning.basic_cleaning(raw_text)\n",
    "characters = sorted(list(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c761734",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(list(set(text)))\n",
    "idx_to_token = dict(enumerate(characters))\n",
    "token_to_idx = {t: i for i, t in enumerate(characters)}\n",
    "encode = lambda s: list(map(token_to_idx.__getitem__, s))\n",
    "decode = lambda s: list(map(idx_to_token.__getitem__, s))\n",
    "data = torch.tensor(encode(text), dtype=torch.long).to(device=device)\n",
    "\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "block_size, batch_size = config.block_size, config.batch_size\n",
    "def get_batch(split):\n",
    "  data = train_data if split == 'train' else val_data\n",
    "  idxs = torch.randint(len(data) - block_size, (batch_size,))\n",
    "  x = torch.stack([data[i:i+block_size] for i in idxs])\n",
    "  y = torch.stack([data[i+1:i+block_size+1] for i in idxs])\n",
    "  return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_val_loss(model):\n",
    "  model.eval()\n",
    "  X, Y = get_batch(\"val\")\n",
    "  X = X.to(device=device)\n",
    "  Y = Y.to(device=device)\n",
    "  _, loss = model(X, Y)\n",
    "  model.train()\n",
    "  return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ee3ff4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m m = gptv1.LanguageModel(\u001b[38;5;28mlen\u001b[39m(characters), config).to(device)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m optimizer = torch.optim.AdamW(m.parameters(), lr=\u001b[32m3e-4\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/apps/toy-gpt/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:3034\u001b[39m, in \u001b[36mModule.compile\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3025\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompile\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   3026\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3027\u001b[39m \u001b[33;03m    Compile this Module's forward using :func:`torch.compile`.\u001b[39;00m\n\u001b[32m   3028\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3032\u001b[39m \u001b[33;03m    See :func:`torch.compile` for details on the arguments for this function.\u001b[39;00m\n\u001b[32m   3033\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3034\u001b[39m     \u001b[38;5;28mself\u001b[39m._compiled_call_impl = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/apps/toy-gpt/venv/lib/python3.11/site-packages/torch/__init__.py:2614\u001b[39m, in \u001b[36mcompile\u001b[39m\u001b[34m(model, fullgraph, dynamic, backend, mode, options, disable)\u001b[39m\n\u001b[32m   2611\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2612\u001b[39m     mode = \u001b[33m\"\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2614\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompiler_bisector\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CompilerBisector\n\u001b[32m   2616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bisect_backend := CompilerBisector.get_backend():\n\u001b[32m   2617\u001b[39m     backend = bisect_backend\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1147\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:690\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:936\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1069\u001b[39m, in \u001b[36mget_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:729\u001b[39m, in \u001b[36m_compile_bytecode\u001b[39m\u001b[34m(data, name, bytecode_path, source_path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "m = gptv1.LanguageModel(len(characters), config).to(device)\n",
    "m.compile()\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=3e-4)\n",
    "import time\n",
    "from torch.amp import autocast\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ce7273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:29<00:00,  6.69it/s, train 1.0835226774215698 val 1.0783356428146362]\n"
     ]
    }
   ],
   "source": [
    "val_loss = -1\n",
    "pbar = tqdm(range(1000))\n",
    "for steps in pbar:\n",
    "\txb, yb = get_batch('train')\n",
    "\txb = xb.to(device)\n",
    "\tyb = yb.to(device)\n",
    "\twith autocast(device_type=\"mps\", dtype=torch.float16):\n",
    "\t\tlogits, loss = m(xb, yb)\n",
    "\toptimizer.zero_grad(set_to_none=True)\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\tif steps % 50 == 0:\n",
    "\t\tval_loss = estimate_val_loss(m)\n",
    "\tpbar.postfix = f\"train {loss.item()} val {val_loss}\"\n",
    "\tpbar.update()\n",
    "\ttorch.mps.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458156b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mind is permissively to amplicate thoughts and conclusive for the experisting in the dream picture, which is question of sleep, every tablishness to asuming from an ansanect is a very percoal; and one only\n"
     ]
    }
   ],
   "source": [
    "idx = torch.tensor([encode(\"The mind \")], dtype=torch.long, device=device)\n",
    "print(\"The mind \", end=\"\", flush=True)\n",
    "for token in m.generate(idx, max_new_tokens=200):\n",
    "\tprint(decode([token.item()])[0], end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4c3b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.128176 M parameters\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34bfce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(m.state_dict(), \"gptv1_sample1.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
