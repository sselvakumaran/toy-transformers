{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "552dd715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('../src')))\n",
    "\n",
    "from utilities import tokenizer2, tokenizer_old\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0349ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../data/freud/interpretation-of-dreams.txt\"\n",
    "input_file = open(filepath, 'r', encoding='utf-8')\n",
    "raw_text = input_file.read()\n",
    "input_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dcc1ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import text_cleaning\n",
    "text = text_cleaning.basic_cleaning(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "415a5eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| | 1| A| An| B| But| C| D| E| F| For| G| H| He| I| If| In| It| L| M| N| O| P| R| S| T| Th| The| This| W| We| _| a| ab| about| abs| ac| acc| account| act| activ| activity| ad| adm| affect| after| ag| again| al| all| already| also| always| am| an| analysis| and| another| any| app| appar| apparatus| appear| ar| are| as| ask| ass| associ| assum| at| att| attention| auth| aw| awaken| b| back| be| bec| because| becom| become| been| before| beg| being| bel| belong| bet| between| bo| br| but| by| c| ca| call| can| cannot| cap| case| cens| censor| certain| ch| char| character| child| childhood| children| cl| cle| co| colle| com| come| comp| comple| con| conc| conce| concer| cond| conf| connect| connection| cons| conscious| consciousness| consider| cont| content| contin| contr| cor| could| course| cr| d| day| de| des| dif| different| difficult| dire| dis| disc| disp| dist| do| does| dream| dreamer| dreams| during| e| ear| ele| elements| em| emot| en| end| ent| est| ev| even| every| ex| exam| exc| exp| experi| experience| expl| explanation| expression| ext| f| fact| far| father| fe| feel| find| fir| first| fl| fo| follow| following| for| fore| form| formation| found| fr| friend| from| ful| fur| further| g| gen| gener| giv| give| go| gr| great| h| ha| had| hand| happ| has| have| he| her| here| him| himself| his| how| however| hy| ide| idea| ideas| if| ill| im| imp| impression| impressions| in| inc| ind| inf| ins| inst| int| inter| interp| interpret| interpretation| into| inv| is| it| its| itself| j| just| k| know| l| lat| later| le| li| life| like| little| lo| long| m| made| make| man| manif| manner| many| mat| material| may| me| mean| means| mem| memory| might| mind| mor| more| most| mot| mother| much| must| my| myself| n| name| ne| neur| never| new| night| no| not| now| num| o| ob| object| obs| occ| occasion| occur| of| often| old| on| once| one| only| op| opp| or| order| org| origin| other| our| out| over| own| p| pain| part| pass| pat| patient| per| person| persons| ph| phant| pict| pictures| pl| place| play| point| poss| possible| pr| pre| present| pro| process| produ| psych| psychic| purp| put| qu| question| quite| r| ra| re| read| real| really| rec| recogn| recolle| ref| reg| rel| relation| relations| rem| rep| represent| repro| res| result| ret| ro| s| sa| same| say| sc| se| second| see| seem| seems| sens| sex| sexual| sh| shall| she| should| show| sign| signific| sim| similar| sleep| so| som| some| somet| something| sour| sp| spe| st| state| still| stimul| stimuli| str| su| sub| subject| such| suff| supp| sy| sym| symbol| system| t| tak| take| taken| th| than| that| the| their| them| then| theory| there| therefore| these| they| think| this| those| thou| though| thought| thoughts| through| thus| tim| time| to| too| tr| tra| trans| treat| tw| two| u| un| unconscious| under| up| upon| us| v| val| very| vis| w| waking| was| way| we| well| were| wh| what| when| where| whether| which| while| who| whom| whose| will| wish| wishes| with| without| wor| word| work| would| y| years| you| young|!|&|(|)|,|-|.|0|1|2|3|4|5|6|7|8|9|:|;|=|?|A|B|C|D|E|F|G|H|I|In|J|K|L|M|N|O|P|Q|R|S|T|The|U|V|W|X|Y|Z|[|]|_|a|ab|able|ably|ac|ach|ack|act|ad|ade|ady|ag|age|ail|ain|ained|ains|air|ak|ake|aken|aking|al|ale|all|ally|alys|alysis|am|ame|an|ance|and|ang|ange|ans|ant|ap|aps|ar|ard|are|arent|ark|arn|art|ary|as|ase|ases|ason|ass|ast|asy|at|ate|ated|ately|ates|ath|ather|atic|ating|ation|ations|ative|ature|atus|au|ause|av|ay|b|ber|ble|bol|c|cc|ce|ced|ceed|cept|ception|ces|cess|ch|ci|cious|ck|con|cond|cons|conscious|ct|ction|d|der|du|e|ear|ears|ec|ect|ed|el|ell|em|empt|en|ence|ences|end|ens|ense|ent|ental|ention|ently|ep|er|ere|ered|eri|erial|erm|ers|ert|ertain|erv|es|ess|est|estion|et|ety|ever|f|fe|ference|ferent|ff|ffect|fic|ficult|fil|filment|fore|form|fter|ful|g|ge|get|gh|ght|h|haps|hat|he|hed|hen|her|hes|hing|hood|i|ial|iar|ib|ible|ic|ical|ice|ich|ick|ict|id|ide|ident|ider|ie|ied|iend|ient|ies|if|ife|ific|ig|ight|igin|ign|il|ilar|ild|ile|ility|ill|ily|im|imul|in|ination|ince|ind|ine|ined|ing|ings|ink|ion|ions|ious|ip|ir|ire|is|ise|ised|isf|ish|ished|ishes|ism|ist|it|ite|ited|ith|ither|ities|ition|itt|ittle|ity|iv|ive|ived|ives|ivid|j|ject|k|ke|l|la|lace|ld|le|led|leep|less|li|ll|llow|lu|ly|m|med|ment|ments|mon|n|ne|nect|ner|ness|ning|not|now|o|ob|od|og|ogn|oin|oint|ok|ol|old|olle|olog|ological|om|ome|on|one|ong|ood|op|or|ord|ording|ore|orm|ors|ort|ory|os|ose|oses|osition|oss|ost|ot|oth|other|ou|oub|ough|ould|oun|ound|oung|ount|our|ourse|ous|ouse|out|ove|ow|ower|own|p|per|ph|pl|ple|pon|pp|pt|qu|r|ra|re|ready|ream|reat|rect|red|ree|ren|rent|res|resent|ress|ressed|ression|ressions|ret|ri|rib|ro|rou|rough|ry|s|se|sel|self|selves|sion|so|soci|son|st|stem|stit|str|sy|sych|t|te|ted|ten|ter|term|th|the|ther|til|to|u|ual|ually|uc|uch|uct|ud|ue|ul|ular|ult|um|un|up|ur|urd|ure|ures|uring|urn|urp|us|usion|ust|ut|uth|ution|v|ve|ved|vel|ver|vers|very|ves|vious|w|ward|way|ways|we|ween|wn|x|xt|y|ys|z|·|Â|Ü|à|ä|æ|ç|è|é|ê|î|ó|ô|ü|œ|Ψ|έ|υ|–|—|‘|’|“|”\n",
      "1015\n"
     ]
    }
   ],
   "source": [
    "td = tokenizer2.create_tokenizer(text, num_tokens=1032)\n",
    "td = tokenizer_old.reduce_token_dictionary(td, text)\n",
    "print(\"|\".join(td.token_set))\n",
    "print(len(td.token_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
