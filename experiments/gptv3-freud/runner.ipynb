{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2597617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch \n",
    "from pathlib import Path\n",
    "\n",
    "def get_project_info() -> Path:\n",
    "  current = Path.cwd().resolve()\n",
    "  root = current\n",
    "  for parent in [current, *current.parents]:\n",
    "    if (parent / \"toy_transformers\").exists():\n",
    "      root = parent\n",
    "      break\n",
    "  return root, current\n",
    "\n",
    "if 'ROOT_DIR' not in globals():\n",
    "\tROOT_DIR, EXPERIMENT_DIR = get_project_info()\n",
    "\tif str(ROOT_DIR) not in sys.path:\n",
    "\t\tsys.path.append(str(ROOT_DIR))\n",
    "\tif Path.cwd() != ROOT_DIR:\n",
    "\t\tos.chdir(ROOT_DIR)\n",
    "\n",
    "from toy_transformers.models import gptv3\n",
    "from toy_transformers import tokenization\n",
    "from toy_transformers import checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca1310df",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 256\n",
    "BATCH_SIZE = 16\n",
    "MODE = tokenization.TokenizationMode.STR\n",
    "DEVICE = \"mps\"\n",
    "\n",
    "config = gptv3.GPTv3Config(\n",
    "\tvocab_size=VOCAB_SIZE,\n",
    "\tblock_size=256,\n",
    "\tdevice=DEVICE,\n",
    "\tn_heads=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23787b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_path = EXPERIMENT_DIR / f\"vocab_{VOCAB_SIZE}.json\"\n",
    "raw_data_path = ROOT_DIR / \"data/gutenberg/freud-interpretation-of-dreams.txt\"\n",
    "\n",
    "if not vocab_path.exists():\n",
    "\traw_data = open(raw_data_path, \"r\")\n",
    "\tvocab = tokenization.create_bpe(\n",
    "\t\traw_data, \n",
    "\t\tVOCAB_SIZE, MODE\n",
    "\t)\n",
    "\tvocab.save(vocab_path)\n",
    "else:\n",
    "\tvocab = tokenization.Vocabulary.load(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbcae302",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(\n",
    "\tvocab.encode(open(raw_data_path, \"r\").read()),\n",
    "\tdtype=torch.long\n",
    ").to(device=DEVICE)\n",
    "\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "block_size, batch_size = config.block_size, BATCH_SIZE\n",
    "def get_batch(split):\n",
    "  data = train_data if split == 'train' else val_data\n",
    "  idxs = torch.randint(len(data) - block_size, (batch_size,), device=DEVICE)\n",
    "  x = torch.stack([data[i:i+block_size] for i in idxs])\n",
    "  y = torch.stack([data[i+1:i+block_size+1] for i in idxs])\n",
    "  return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_val_loss(model):\n",
    "  model.eval()\n",
    "  X, Y = get_batch(\"val\")\n",
    "  _, loss = model(X, Y)\n",
    "  model.train()\n",
    "  return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfc13aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "m = gptv3.LanguageModel(config).to(device=DEVICE)\n",
    "m.compile()\n",
    "\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "  optimizer,\n",
    "  mode='min',\n",
    "  factor=0.1,\n",
    "  patience=10\n",
    ")\n",
    "\n",
    "import time\n",
    "from torch.amp import autocast\n",
    "from tqdm import tqdm\n",
    "\n",
    "@torch.compile(fullgraph=False)\n",
    "def opt_step():\n",
    "\toptimizer.step()\n",
    "\n",
    "\n",
    "TOTAL_STEPS = 5000\n",
    "CKPT_DIR = EXPERIMENT_DIR / \"checkpoints\"\n",
    "TRAINING_CONFIG = {\n",
    "\t\"lr\": 3e-4, \n",
    "\t\"batch_size\": BATCH_SIZE, \"vocab_path\": str(vocab_path)\n",
    "}\n",
    "\n",
    "metrics = []\n",
    "step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a2e7c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 4.193595886230469 4.462152481079102\n",
      "100 3.81711483001709 4.183409214019775\n",
      "150 3.8217692375183105 4.0282440185546875\n",
      "200 3.7593436241149902 3.9035584926605225\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m step < TOTAL_STEPS:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \txb, yb = \u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \t\u001b[38;5;28;01mwith\u001b[39;00m autocast(device_type=DEVICE, dtype=torch.float16):\n\u001b[32m      4\u001b[39m \t\tlogits, loss = m(xb, yb)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mget_batch\u001b[39m\u001b[34m(split)\u001b[39m\n\u001b[32m     12\u001b[39m data = train_data \u001b[38;5;28;01mif\u001b[39;00m split == \u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m val_data\n\u001b[32m     13\u001b[39m idxs = torch.randint(\u001b[38;5;28mlen\u001b[39m(data) - block_size, (batch_size,), device=DEVICE)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m x = torch.stack(\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midxs\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m     15\u001b[39m y = torch.stack([data[i+\u001b[32m1\u001b[39m:i+block_size+\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idxs])\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     12\u001b[39m data = train_data \u001b[38;5;28;01mif\u001b[39;00m split == \u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m val_data\n\u001b[32m     13\u001b[39m idxs = torch.randint(\u001b[38;5;28mlen\u001b[39m(data) - block_size, (batch_size,), device=DEVICE)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m x = torch.stack([data[i:i+block_size] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idxs])\n\u001b[32m     15\u001b[39m y = torch.stack([data[i+\u001b[32m1\u001b[39m:i+block_size+\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idxs])\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "while step < TOTAL_STEPS:\n",
    "\txb, yb = get_batch('train')\n",
    "\twith autocast(device_type=DEVICE, dtype=torch.float16):\n",
    "\t\tlogits, loss = m(xb, yb)\n",
    "\toptimizer.zero_grad(set_to_none=True)\n",
    "\tloss.backward()\n",
    "\topt_step()\n",
    "\n",
    "\tif step % 10 != 0: \n",
    "\t\tstep += 1\n",
    "\t\tcontinue\n",
    "\n",
    "\trow = {\"step\": step, \"train_loss\": loss.item()}\n",
    "\tif step % 50 == 0:\n",
    "\t\trow[\"val_loss\"] = estimate_val_loss(m)\n",
    "\t\tscheduler.step(row[\"val_loss\"])\n",
    "\t\tprint(step, row.get(\"train_loss\"), row.get(\"val_loss\"))\n",
    "\tmetrics.append(row)\n",
    "\t\n",
    "\tif step % 1000 == 0:\n",
    "\t\tcheckpoint.save(\n",
    "\t\t\tCKPT_DIR / f\"step-{step}\",\n",
    "\t\t\tm, config, TRAINING_CONFIG, metrics, optimizer=optimizer, scheduler=scheduler\n",
    "\t\t)\n",
    "\t\tprint(f\"saved /checkpoints/step-{step}\")\n",
    "\n",
    "\tstep += 1\n",
    "\n",
    "checkpoint.save(\n",
    "\tCKPT_DIR / \"final\", \n",
    "\tm, config, TRAINING_CONFIG, \n",
    "\tmetrics, \n",
    "\toptimizer=optimizer, scheduler=scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de620972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 36, 126, 145, 129,  47]], device='mps:0')\n",
      "The mind  to itself allows to reproduce on the dreamer has urinattensely with a relation to all scene impressions“He I fear that about just as to the first I make myself art you youth dream when shewas a short patient to hiscause her submbles“milike it your man her first impes at nightI was a going to adterminit friend whenhe has made they are not heard and really treating it of the punished hada\n"
     ]
    }
   ],
   "source": [
    "idx = torch.tensor([vocab.encode(\"The mind \")], dtype=torch.long, device=DEVICE)\n",
    "print(idx)\n",
    "print(\"The mind \", end=\"\", flush=True)\n",
    "for token in m.generate(idx, max_new_tokens=200):\n",
    "\tprint(vocab.decode([token.item()])[0], end=\"\", flush=True)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
