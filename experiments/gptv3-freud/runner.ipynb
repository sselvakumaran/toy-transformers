{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2597617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch \n",
    "from pathlib import Path\n",
    "\n",
    "def get_project_info() -> Path:\n",
    "  current = Path.cwd().resolve()\n",
    "  root = current\n",
    "  for parent in [current, *current.parents]:\n",
    "    if (parent / \"toy_transformers\").exists():\n",
    "      root = parent\n",
    "      break\n",
    "  return root, current\n",
    "\n",
    "if 'ROOT_DIR' not in globals():\n",
    "\tROOT_DIR, EXPERIMENT_DIR = get_project_info()\n",
    "\tif str(ROOT_DIR) not in sys.path:\n",
    "\t\tsys.path.append(str(ROOT_DIR))\n",
    "\tif Path.cwd() != ROOT_DIR:\n",
    "\t\tos.chdir(ROOT_DIR)\n",
    "\n",
    "from toy_transformers.models import gptv3\n",
    "from toy_transformers import tokenization\n",
    "from toy_transformers import checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca1310df",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 256\n",
    "BATCH_SIZE = 16\n",
    "MODE = tokenization.TokenizationMode.STR\n",
    "DEVICE = \"mps\"\n",
    "\n",
    "config = gptv3.GPTv3Config(\n",
    "\tvocab_size=VOCAB_SIZE,\n",
    "\tblock_size=256,\n",
    "\tdevice=DEVICE,\n",
    "\tn_heads=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23787b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_path = EXPERIMENT_DIR / f\"vocab_{VOCAB_SIZE}.json\"\n",
    "raw_data_path = ROOT_DIR / \"data/gutenberg/freud-interpretation-of-dreams.txt\"\n",
    "\n",
    "if not vocab_path.exists():\n",
    "\traw_data = open(raw_data_path, \"r\")\n",
    "\tvocab = tokenization.create_bpe(\n",
    "\t\traw_data, \n",
    "\t\tVOCAB_SIZE, MODE\n",
    "\t)\n",
    "\tvocab.save(vocab_path)\n",
    "else:\n",
    "\tvocab = tokenization.Vocabulary.load(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbcae302",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(\n",
    "\tvocab.encode(open(raw_data_path, \"r\").read()),\n",
    "\tdtype=torch.long\n",
    ").to(device=DEVICE)\n",
    "\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "block_size, batch_size = config.block_size, BATCH_SIZE\n",
    "def get_batch(split):\n",
    "  data = train_data if split == 'train' else val_data\n",
    "  idxs = torch.randint(len(data) - block_size, (batch_size,), device=DEVICE)\n",
    "  x = torch.stack([data[i:i+block_size] for i in idxs])\n",
    "  y = torch.stack([data[i+1:i+block_size+1] for i in idxs])\n",
    "  return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_val_loss(model):\n",
    "  model.eval()\n",
    "  X, Y = get_batch(\"val\")\n",
    "  _, loss = model(X, Y)\n",
    "  model.train()\n",
    "  return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfc13aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "m = gptv3.LanguageModel(config).to(device=DEVICE)\n",
    "m.compile()\n",
    "\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "  optimizer,\n",
    "  mode='min',\n",
    "  factor=0.1,\n",
    "  patience=10\n",
    ")\n",
    "\n",
    "import time\n",
    "from torch.amp import autocast\n",
    "from tqdm import tqdm\n",
    "\n",
    "@torch.compile(fullgraph=False)\n",
    "def opt_step():\n",
    "\toptimizer.step()\n",
    "\n",
    "\n",
    "TOTAL_STEPS = 5000\n",
    "CKPT_DIR = EXPERIMENT_DIR / \"checkpoints\"\n",
    "TRAINING_CONFIG = {\n",
    "\t\"lr\": 3e-4, \n",
    "\t\"batch_size\": BATCH_SIZE, \"vocab_path\": str(vocab_path)\n",
    "}\n",
    "\n",
    "metrics = []\n",
    "step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a2e7c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0219 11:48:49.627000 41235 torch/_inductor/utils.py:1436] [0/0] Not enough SMs to use max_autotune_gemm mode\n",
      "W0219 11:48:52.784000 41235 torch/_logging/_internal.py:1154] [1/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 4.384234428405762 4.648870468139648\n",
      "100 4.047226905822754 4.139969825744629\n",
      "150 3.7820019721984863 4.086138725280762\n",
      "200 3.7535905838012695 3.92063307762146\n",
      "250 3.6739964485168457 3.921074390411377\n",
      "300 3.645641565322876 3.9194817543029785\n",
      "350 3.634645462036133 3.8154044151306152\n",
      "400 3.6066665649414062 3.8864126205444336\n",
      "450 3.584534168243408 3.7719945907592773\n",
      "500 3.648094892501831 3.7483103275299072\n",
      "550 3.6554043292999268 3.7068026065826416\n",
      "600 3.5686092376708984 3.708644151687622\n",
      "650 3.5130562782287598 3.7643392086029053\n",
      "700 3.5106019973754883 3.672624111175537\n",
      "750 3.5582845211029053 3.7181248664855957\n",
      "800 3.495180130004883 3.605212450027466\n",
      "850 3.468641757965088 3.7021896839141846\n",
      "900 3.320737361907959 3.628838062286377\n",
      "950 3.358198642730713 3.6623711585998535\n",
      "1000 3.3235650062561035 3.522066593170166\n",
      "saved /checkpoints/step-1000\n",
      "1050 3.3326032161712646 3.491982936859131\n",
      "1100 3.1019415855407715 3.519822359085083\n",
      "1150 3.122255802154541 3.4177074432373047\n",
      "1200 3.042525053024292 3.2906651496887207\n",
      "1250 3.0401341915130615 3.3148293495178223\n",
      "1300 2.992272138595581 3.2353732585906982\n",
      "1350 2.8583264350891113 3.3380610942840576\n",
      "1400 2.9662866592407227 3.281829595565796\n",
      "1450 2.873518466949463 3.131793737411499\n",
      "1500 2.7672221660614014 3.3106093406677246\n",
      "1550 2.7420361042022705 3.245201826095581\n",
      "1600 2.722972869873047 3.0772368907928467\n",
      "1650 2.7040369510650635 3.145139455795288\n",
      "1700 2.6809496879577637 3.3280959129333496\n",
      "1750 2.6955270767211914 3.025722026824951\n",
      "1800 2.695629596710205 3.1354503631591797\n",
      "1850 2.7396514415740967 3.1012187004089355\n",
      "1900 2.5928168296813965 3.116727590560913\n",
      "1950 2.65899658203125 2.956843852996826\n",
      "2000 2.5589935779571533 3.1384148597717285\n",
      "saved /checkpoints/step-2000\n",
      "2050 2.5592474937438965 3.2150261402130127\n",
      "2100 2.640326499938965 3.2934975624084473\n",
      "2150 2.546210765838623 3.25998854637146\n",
      "2200 2.5689079761505127 3.105128288269043\n",
      "2250 2.52874493598938 3.048811435699463\n",
      "2300 2.5072031021118164 3.0501785278320312\n",
      "2350 2.4568099975585938 3.056309938430786\n",
      "2400 2.476411819458008 2.967890739440918\n",
      "2450 2.40950870513916 2.899862051010132\n",
      "2500 2.4522104263305664 2.968705654144287\n",
      "2550 2.412064552307129 3.0564522743225098\n",
      "2600 2.4731996059417725 3.268425941467285\n",
      "2650 2.40616512298584 3.1332855224609375\n",
      "2700 2.488025188446045 2.937990188598633\n",
      "2750 2.3804383277893066 2.942695140838623\n",
      "2800 2.3771603107452393 3.0469980239868164\n",
      "2850 2.3825526237487793 2.918195962905884\n",
      "2900 2.378556728363037 2.802910327911377\n",
      "2950 2.316192626953125 3.032156467437744\n",
      "3000 2.4825267791748047 2.9144058227539062\n",
      "saved /checkpoints/step-3000\n",
      "3050 2.4085421562194824 3.0414998531341553\n",
      "3100 2.3099374771118164 2.822309970855713\n",
      "3150 2.4470629692077637 3.1023707389831543\n",
      "3200 2.3498730659484863 2.9655778408050537\n",
      "3250 2.343341588973999 2.9192404747009277\n",
      "3300 2.23690128326416 3.2177867889404297\n",
      "3350 2.4174346923828125 2.931333065032959\n",
      "3400 2.3307454586029053 2.8924665451049805\n",
      "3450 2.2570838928222656 2.994187831878662\n",
      "3500 2.163212299346924 2.818850517272949\n",
      "3550 2.257366895675659 2.8957436084747314\n",
      "3600 2.2373270988464355 2.9484286308288574\n",
      "3650 2.136803388595581 3.262223720550537\n",
      "3700 2.1862411499023438 2.962538003921509\n",
      "3750 2.1847116947174072 2.90105938911438\n",
      "3800 2.1779708862304688 2.8076696395874023\n",
      "3850 2.2240548133850098 2.830047130584717\n",
      "3900 2.135655403137207 2.92883563041687\n",
      "3950 2.1648452281951904 3.1205079555511475\n",
      "4000 2.2372193336486816 2.710574150085449\n",
      "saved /checkpoints/step-4000\n",
      "4050 2.2375693321228027 2.9254329204559326\n",
      "4100 2.1645331382751465 2.7962846755981445\n",
      "4150 2.1779184341430664 2.9038970470428467\n",
      "4200 2.1929914951324463 2.972219228744507\n",
      "4250 2.2029666900634766 2.7751388549804688\n",
      "4300 2.1429567337036133 3.011608600616455\n",
      "4350 2.2272398471832275 2.921100378036499\n",
      "4400 2.2169647216796875 2.6512081623077393\n",
      "4450 2.085291862487793 2.866865634918213\n",
      "4500 2.234835624694824 3.0150609016418457\n",
      "4550 2.223222494125366 2.965031623840332\n",
      "4600 2.1947426795959473 3.111311674118042\n",
      "4650 2.111046314239502 3.0063037872314453\n",
      "4700 2.172377109527588 3.115432024002075\n",
      "4750 2.082646369934082 2.7950050830841064\n",
      "4800 2.2069766521453857 3.029379367828369\n",
      "4850 2.1560730934143066 2.8667609691619873\n",
      "4900 2.1254382133483887 3.0828027725219727\n",
      "4950 2.0565476417541504 2.875138521194458\n"
     ]
    }
   ],
   "source": [
    "while step < TOTAL_STEPS:\n",
    "\txb, yb = get_batch('train')\n",
    "\twith autocast(device_type=DEVICE, dtype=torch.float16):\n",
    "\t\tlogits, loss = m(xb, yb)\n",
    "\toptimizer.zero_grad(set_to_none=True)\n",
    "\tloss.backward()\n",
    "\topt_step()\n",
    "\n",
    "\tif step % 10 != 0: \n",
    "\t\tstep += 1\n",
    "\t\tcontinue\n",
    "\n",
    "\trow = {\"step\": step, \"train_loss\": loss.item()}\n",
    "\tif step % 50 == 0:\n",
    "\t\trow[\"val_loss\"] = estimate_val_loss(m)\n",
    "\t\tscheduler.step(row[\"val_loss\"])\n",
    "\t\tprint(step, row.get(\"train_loss\"), row.get(\"val_loss\"))\n",
    "\tmetrics.append(row)\n",
    "\t\n",
    "\tif step % 1000 == 0:\n",
    "\t\tcheckpoint.save(\n",
    "\t\t\tCKPT_DIR / f\"step-{step}\",\n",
    "\t\t\tm, config, TRAINING_CONFIG, metrics, optimizer=optimizer, scheduler=scheduler\n",
    "\t\t)\n",
    "\t\tprint(f\"saved /checkpoints/step-{step}\")\n",
    "\n",
    "\tstep += 1\n",
    "\n",
    "checkpoint.save(\n",
    "\tCKPT_DIR / \"final\", \n",
    "\tm, config, TRAINING_CONFIG, \n",
    "\tmetrics, \n",
    "\toptimizer=optimizer, scheduler=scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4cfb9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loading checkpoint\n",
    "m, config, training_config, metrics, opt_state, sched_state = checkpoint.load(\n",
    "\tCKPT_DIR / \"final\",\n",
    "\tgptv3.LanguageModel, gptv3.GPTv3Config, device=DEVICE, \n",
    ")\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=training_config[\"lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "\toptimizer, mode='min', factor=0.1, patience=10\n",
    ")\n",
    "if opt_state: optimizer.load_state_dict(opt_state)\n",
    "if sched_state: scheduler.load_state_dict(sched_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de620972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 36, 126, 145, 129,  47]], device='mps:0')\n",
      "The mind  to itself allows to reproduce on the dreamer has urinattensely with a relation to all scene impressions“He I fear that about just as to the first I make myself art you youth dream when shewas a short patient to hiscause her submbles“milike it your man her first impes at nightI was a going to adterminit friend whenhe has made they are not heard and really treating it of the punished hada\n"
     ]
    }
   ],
   "source": [
    "idx = torch.tensor([vocab.encode(\"The mind \")], dtype=torch.long, device=DEVICE)\n",
    "print(idx)\n",
    "print(\"The mind \", end=\"\", flush=True)\n",
    "for token in m.generate(idx, max_new_tokens=200):\n",
    "\tprint(vocab.decode([token.item()])[0], end=\"\", flush=True)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
