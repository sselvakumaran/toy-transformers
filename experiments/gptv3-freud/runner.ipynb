{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2597617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch \n",
    "from pathlib import Path\n",
    "\n",
    "def get_project_info() -> Path:\n",
    "  current = Path.cwd().resolve()\n",
    "  root = current\n",
    "  for parent in [current, *current.parents]:\n",
    "    if (parent / \"toy_transformers\").exists():\n",
    "      root = parent\n",
    "      break\n",
    "  return root, current\n",
    "\n",
    "if 'ROOT_DIR' not in globals():\n",
    "\tROOT_DIR, EXPERIMENT_DIR = get_project_info()\n",
    "\tif str(ROOT_DIR) not in sys.path:\n",
    "\t\tsys.path.append(str(ROOT_DIR))\n",
    "\tif Path.cwd() != ROOT_DIR:\n",
    "\t\tos.chdir(ROOT_DIR)\n",
    "\n",
    "from toy_transformers.models import gptv3\n",
    "from toy_transformers import tokenization\n",
    "from toy_transformers import checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca1310df",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 256\n",
    "BATCH_SIZE = 16\n",
    "MODE = tokenization.TokenizationMode.STR\n",
    "DEVICE = \"mps\"\n",
    "\n",
    "config = gptv3.GPTv3Config(\n",
    "\tvocab_size=VOCAB_SIZE,\n",
    "\tblock_size=256,\n",
    "\tdevice=DEVICE,\n",
    "\tn_heads=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23787b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_path = EXPERIMENT_DIR / f\"vocab_{VOCAB_SIZE}.json\"\n",
    "raw_data_path = ROOT_DIR / \"data/gutenberg/freud-interpretation-of-dreams.txt\"\n",
    "\n",
    "if not vocab_path.exists():\n",
    "\traw_data = open(raw_data_path, \"r\")\n",
    "\tvocab = tokenization.create_bpe(\n",
    "\t\traw_data, \n",
    "\t\tVOCAB_SIZE, MODE\n",
    "\t)\n",
    "\tvocab.save(vocab_path)\n",
    "else:\n",
    "\tvocab = tokenization.Vocabulary.load(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbcae302",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(\n",
    "\tvocab.encode(open(raw_data_path, \"r\").read()),\n",
    "\tdtype=torch.long\n",
    ").to(device=DEVICE)\n",
    "\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "block_size, batch_size = config.block_size, BATCH_SIZE\n",
    "def get_batch(split):\n",
    "  data = train_data if split == 'train' else val_data\n",
    "  idxs = torch.randint(len(data) - block_size, (batch_size,), device=DEVICE)\n",
    "  x = torch.stack([data[i:i+block_size] for i in idxs])\n",
    "  y = torch.stack([data[i+1:i+block_size+1] for i in idxs])\n",
    "  return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_val_loss(model):\n",
    "  model.eval()\n",
    "  X, Y = get_batch(\"val\")\n",
    "  _, loss = model(X, Y)\n",
    "  model.train()\n",
    "  return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfc13aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "m = gptv3.LanguageModel(config).to(device=DEVICE)\n",
    "m.compile()\n",
    "\n",
    "optimizer = m.get_optimizer(weight_decay=0.1, lr=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "  optimizer,\n",
    "  mode='min',\n",
    "  factor=0.1,\n",
    "  patience=10\n",
    ")\n",
    "\n",
    "from torch.amp import autocast\n",
    "\n",
    "@torch.compile(fullgraph=False)\n",
    "def opt_step():\n",
    "\toptimizer.step()\n",
    "\n",
    "\n",
    "TOTAL_STEPS = 5000\n",
    "CKPT_DIR: Path = EXPERIMENT_DIR / \"checkpoints\"\n",
    "TRAINING_CONFIG = {\n",
    "\t\"lr\": 3e-4, \n",
    "\t\"batch_size\": BATCH_SIZE, \"vocab_path\": str(vocab_path)\n",
    "}\n",
    "\n",
    "metrics = []\n",
    "step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a2e7c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0219 15:48:33.021000 71864 torch/_logging/_internal.py:1154] [1/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 3.91800594329834 4.19514274597168\n",
      "100 3.633840560913086 3.9798569679260254\n",
      "150 3.2122802734375 3.6354613304138184\n",
      "200 2.771958589553833 3.237701416015625\n",
      "250 2.6974315643310547 3.3200511932373047\n",
      "300 2.592297077178955 3.0565438270568848\n",
      "350 2.490304470062256 3.1327829360961914\n",
      "400 2.4168834686279297 2.778806447982788\n",
      "450 2.466536045074463 2.9609217643737793\n",
      "500 2.36013126373291 3.0146431922912598\n",
      "550 2.25425386428833 2.966062545776367\n",
      "600 2.258500099182129 2.9977903366088867\n",
      "650 2.231710910797119 2.944746732711792\n",
      "700 2.251190662384033 2.9492666721343994\n",
      "750 2.123166561126709 2.8822574615478516\n",
      "800 2.1107873916625977 2.909810781478882\n",
      "850 1.987457036972046 2.9613428115844727\n",
      "900 1.9929145574569702 3.076072931289673\n",
      "950 1.9082441329956055 2.8268110752105713\n",
      "1000 1.906280517578125 2.895228147506714\n",
      "1050 1.8253810405731201 2.8321151733398438\n",
      "1100 1.9529666900634766 2.568094491958618\n",
      "1150 1.782371997833252 2.98931622505188\n",
      "1200 1.8500678539276123 2.971012592315674\n",
      "1250 1.740368366241455 2.948139190673828\n",
      "1300 1.7585580348968506 3.065304756164551\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m step < TOTAL_STEPS:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \txb, yb = \u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \t\u001b[38;5;28;01mwith\u001b[39;00m autocast(device_type=DEVICE, dtype=torch.bfloat16):\n\u001b[32m      4\u001b[39m \t\tlogits, loss = m(xb, yb)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mget_batch\u001b[39m\u001b[34m(split)\u001b[39m\n\u001b[32m     12\u001b[39m data = train_data \u001b[38;5;28;01mif\u001b[39;00m split == \u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m val_data\n\u001b[32m     13\u001b[39m idxs = torch.randint(\u001b[38;5;28mlen\u001b[39m(data) - block_size, (batch_size,), device=DEVICE)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m x = torch.stack(\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midxs\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m     15\u001b[39m y = torch.stack([data[i+\u001b[32m1\u001b[39m:i+block_size+\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idxs])\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     12\u001b[39m data = train_data \u001b[38;5;28;01mif\u001b[39;00m split == \u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m val_data\n\u001b[32m     13\u001b[39m idxs = torch.randint(\u001b[38;5;28mlen\u001b[39m(data) - block_size, (batch_size,), device=DEVICE)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m x = torch.stack([data[i:i+block_size] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idxs])\n\u001b[32m     15\u001b[39m y = torch.stack([data[i+\u001b[32m1\u001b[39m:i+block_size+\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idxs])\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "while step < TOTAL_STEPS:\n",
    "\txb, yb = get_batch('train')\n",
    "\twith autocast(device_type=DEVICE, dtype=torch.bfloat16):\n",
    "\t\tlogits, loss = m(xb, yb)\n",
    "\toptimizer.zero_grad(set_to_none=True)\n",
    "\tloss.backward()\n",
    "\ttorch.nn.utils.clip_grad_norm_(m.parameters(), 1.0)\n",
    "\topt_step()\n",
    "\n",
    "\tif step % 10 != 0: \n",
    "\t\tstep += 1\n",
    "\t\tcontinue\n",
    "\n",
    "\trow = {\"step\": step, \"train_loss\": loss.item()}\n",
    "\tif step % 50 == 0:\n",
    "\t\trow[\"val_loss\"] = estimate_val_loss(m)\n",
    "\t\tscheduler.step(row[\"val_loss\"])\n",
    "\t\tprint(step, row.get(\"train_loss\"), row.get(\"val_loss\"))\n",
    "\tmetrics.append(row)\n",
    "\t\n",
    "\t# if step % 1000 == 0:\n",
    "\t# \tcheckpoint.save(\n",
    "\t# \t\tCKPT_DIR / f\"step-{step}\",\n",
    "\t# \t\tm, config, TRAINING_CONFIG, metrics, optimizer=optimizer, scheduler=scheduler\n",
    "\t# \t)\n",
    "\t# \tprint(f\"saved /checkpoints/step-{step}\")\n",
    "\n",
    "\tstep += 1\n",
    "\n",
    "# checkpoint.save(\n",
    "# \tCKPT_DIR / \"final\", \n",
    "# \tm, config, TRAINING_CONFIG, \n",
    "# \tmetrics, \n",
    "# \toptimizer=optimizer, scheduler=scheduler\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de620972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 36, 126, 145, 129,  47]], device='mps:0')\n",
      "The mind  w"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sselva890@cable.comcast.com/dev/apps/toy-transformers/venv/lib/python3.11/site-packages/torch/_dynamo/utils.py:3421: UserWarning: record_context_cpp is not support on non-linux non-x86_64 platforms (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/profiler/unwind/unwind.cpp:12.)\n",
      "  return node.target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as cleaphocontent a profond aconnectionthe in thefulfilment of his fathersThe condensation had mentioned during the way to that we had-called each with the exceused that upon it oneof followedexperience in friend which would have us an enablealoccur in meition\n",
      "\n",
      "The same room and a distance which they can be told in the dream is not a wish as long as it were necessary for the motive for the dreaming mind This a wish We have a\n"
     ]
    }
   ],
   "source": [
    "idx = torch.tensor([vocab.encode(\"The mind \")], dtype=torch.long, device=DEVICE)\n",
    "print(idx)\n",
    "print(\"The mind \", end=\"\", flush=True)\n",
    "for token in m.generate(idx, max_new_tokens=200):\n",
    "\tprint(vocab.decode([token.item()])[0], end=\"\", flush=True)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
