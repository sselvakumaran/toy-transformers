{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2597617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch \n",
    "from pathlib import Path\n",
    "\n",
    "def get_project_info() -> Path:\n",
    "  current = Path.cwd().resolve()\n",
    "  root = current\n",
    "  for parent in [current, *current.parents]:\n",
    "    if (parent / \"toy_transformers\").exists():\n",
    "      root = parent\n",
    "      break\n",
    "  return root, current\n",
    "\n",
    "if 'ROOT_DIR' not in globals():\n",
    "\tROOT_DIR, EXPERIMENT_DIR = get_project_info()\n",
    "\tif str(ROOT_DIR) not in sys.path:\n",
    "\t\tsys.path.append(str(ROOT_DIR))\n",
    "\tif Path.cwd() != ROOT_DIR:\n",
    "\t\tos.chdir(ROOT_DIR)\n",
    "\n",
    "from toy_transformers.models import gptv1\n",
    "from toy_transformers import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca1310df",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 256\n",
    "BATCH_SIZE = 16\n",
    "MODE = tokenization.TokenizationMode.STR\n",
    "DEVICE = \"mps\"\n",
    "\n",
    "config = gptv1.GPTv1Config(\n",
    "\tvocab_size=VOCAB_SIZE,\n",
    "\tblock_size=256,\n",
    "\tdevice=DEVICE,\n",
    "\tn_heads=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23787b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_path = EXPERIMENT_DIR / f\"vocab_{VOCAB_SIZE}.json\"\n",
    "raw_data_path = ROOT_DIR / \"data/gutenberg/freud-interpretation-of-dreams.txt\"\n",
    "\n",
    "if not vocab_path.exists():\n",
    "\traw_data = open(raw_data_path, \"r\")\n",
    "\tvocab = tokenization.create_bpe(\n",
    "\t\traw_data, \n",
    "\t\tVOCAB_SIZE, MODE\n",
    "\t)\n",
    "\tvocab.save(vocab_path)\n",
    "else:\n",
    "\tvocab = tokenization.Vocabulary.load(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbcae302",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(\n",
    "\tvocab.encode(open(raw_data_path, \"r\").read()),\n",
    "\tdtype=torch.long\n",
    ").to(device=DEVICE)\n",
    "\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "block_size, batch_size = config.block_size, BATCH_SIZE\n",
    "def get_batch(split):\n",
    "  data = train_data if split == 'train' else val_data\n",
    "  idxs = torch.randint(len(data) - block_size, (batch_size,), device=DEVICE)\n",
    "  x = torch.stack([data[i:i+block_size] for i in idxs])\n",
    "  y = torch.stack([data[i+1:i+block_size+1] for i in idxs])\n",
    "  return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_val_loss(model):\n",
    "  model.eval()\n",
    "  X, Y = get_batch(\"val\")\n",
    "  _, loss = model(X, Y)\n",
    "  model.train()\n",
    "  return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfc13aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "m = gptv1.LanguageModel(config).to(device=DEVICE)\n",
    "m.compile()\n",
    "\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "  optimizer,\n",
    "  mode='min',\n",
    "  factor=0.1,\n",
    "  patience=10\n",
    ")\n",
    "\n",
    "import time\n",
    "from torch.amp import autocast\n",
    "from tqdm import tqdm\n",
    "\n",
    "@torch.compile(fullgraph=False)\n",
    "def opt_step():\n",
    "\toptimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a2e7c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.8628978729248047 3.2616634368896484\n",
      "25 3.0183637142181396 None\n",
      "50 2.962312698364258 3.2225286960601807\n",
      "75 2.888119697570801 None\n",
      "100 2.920164108276367 3.3332157135009766\n",
      "125 2.948301076889038 None\n",
      "150 2.8485748767852783 3.133199453353882\n",
      "175 2.8420910835266113 None\n",
      "200 2.796180486679077 3.0181374549865723\n",
      "225 2.91645884513855 None\n",
      "250 2.892462730407715 3.216552734375\n",
      "275 2.850684404373169 None\n",
      "300 2.6719589233398438 3.2438554763793945\n",
      "325 2.7837882041931152 None\n",
      "350 2.8367955684661865 3.1557326316833496\n",
      "375 2.6888136863708496 None\n",
      "400 2.7636306285858154 3.1481988430023193\n",
      "425 2.6931753158569336 None\n",
      "450 2.747929573059082 3.203716278076172\n",
      "475 2.579789161682129 None\n",
      "500 2.72352933883667 3.271591901779175\n",
      "525 2.6106324195861816 None\n",
      "550 2.5243115425109863 3.266279697418213\n",
      "575 2.6501262187957764 None\n",
      "600 2.634244918823242 3.0115363597869873\n",
      "625 2.742239475250244 None\n",
      "650 2.664534091949463 3.086094856262207\n",
      "675 2.7224597930908203 None\n",
      "700 2.670586585998535 3.0264275074005127\n",
      "725 2.594926357269287 None\n",
      "750 2.633800506591797 3.154940605163574\n",
      "775 2.512716770172119 None\n",
      "800 2.5863935947418213 3.194145679473877\n",
      "825 2.665893077850342 None\n",
      "850 2.6543049812316895 3.084745168685913\n",
      "875 2.411057472229004 None\n",
      "900 2.5986428260803223 3.1461215019226074\n",
      "925 2.5827717781066895 None\n",
      "950 2.5195751190185547 2.9253005981445312\n",
      "975 2.533543586730957 None\n",
      "1000 2.587247371673584 2.8219027519226074\n",
      "1025 2.549086093902588 None\n",
      "1050 2.556272029876709 3.0716590881347656\n",
      "1075 2.6077656745910645 None\n",
      "1100 2.5470407009124756 3.007587432861328\n",
      "1125 2.398878335952759 None\n",
      "1150 2.4462738037109375 3.07521915435791\n",
      "1175 2.42448091506958 None\n",
      "1200 2.506013870239258 2.7655420303344727\n",
      "1225 2.426025867462158 None\n",
      "1250 2.5164480209350586 3.152503490447998\n",
      "1275 2.5861892700195312 None\n",
      "1300 2.4110641479492188 3.037254571914673\n",
      "1325 2.5591812133789062 None\n",
      "1350 2.4758963584899902 3.124685764312744\n",
      "1375 2.4185361862182617 None\n",
      "1400 2.4474735260009766 2.8558850288391113\n",
      "1425 2.4055919647216797 None\n",
      "1450 2.44948148727417 3.1552810668945312\n",
      "1475 2.479825496673584 None\n",
      "1500 2.3903887271881104 2.900634527206421\n",
      "1525 2.499818801879883 None\n",
      "1550 2.433095932006836 3.091548442840576\n",
      "1575 2.508981704711914 None\n",
      "1600 2.3741910457611084 2.903663396835327\n",
      "1625 2.4435009956359863 None\n",
      "1650 2.3908843994140625 3.0954880714416504\n",
      "1675 2.4761013984680176 None\n",
      "1700 2.266373872756958 3.0270917415618896\n",
      "1725 2.5194191932678223 None\n",
      "1750 2.362497568130493 3.156557083129883\n",
      "1775 2.395909547805786 None\n",
      "1800 2.298067092895508 3.0080478191375732\n",
      "1825 2.4042866230010986 None\n",
      "1850 2.408219337463379 3.1392221450805664\n",
      "1875 2.3272757530212402 None\n",
      "1900 2.4494569301605225 3.1439332962036133\n",
      "1925 2.338820457458496 None\n",
      "1950 2.286623954772949 2.8315720558166504\n",
      "1975 2.235635757446289 None\n"
     ]
    }
   ],
   "source": [
    "for steps in range(2000):\n",
    "\txb, yb = get_batch('train')\n",
    "\twith autocast(device_type=DEVICE, dtype=torch.float16):\n",
    "\t\tlogits, loss = m(xb, yb)\n",
    "\toptimizer.zero_grad(set_to_none=True)\n",
    "\tloss.backward()\n",
    "\topt_step()\n",
    "\ttrain_loss, val_loss = loss.item(), None\n",
    "\tif steps % 50 == 0:\n",
    "\t\tval_loss = estimate_val_loss(m)\n",
    "\t\tscheduler.step(val_loss)\n",
    "\t\n",
    "\tif steps % 25 == 0:\n",
    "\t\tprint(steps, train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de620972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 36, 126, 145, 129,  47]], device='mps:0')\n",
      "The mind uring upon will concerned with severalsymaterial for thegeticper outsers mayhis own dreams From thisin their assume one is indeft the birth-fulfilment\n",
      "\n",
      "The BsShe is susponsible to be having to attrave she to fall the kind parents motor for theunconsciousand of the night in great she children[CQ\n",
      "\n",
      "MyserMsather(Cheddenous who has beencause so safeeling a came for for his Ih\n"
     ]
    }
   ],
   "source": [
    "idx = torch.tensor([vocab.encode(\"The mind \")], dtype=torch.long, device=DEVICE)\n",
    "print(idx)\n",
    "print(\"The mind \", end=\"\", flush=True)\n",
    "for token in m.generate(idx, max_new_tokens=200):\n",
    "\tprint(vocab.decode([token.item()])[0], end=\"\", flush=True)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
