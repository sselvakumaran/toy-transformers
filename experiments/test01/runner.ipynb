{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb910ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def get_project_info() -> Path:\n",
    "  current = Path.cwd().resolve()\n",
    "  root = current\n",
    "  for parent in [current, *current.parents]:\n",
    "    if (parent / \"toy_transformers\").exists():\n",
    "      root = parent\n",
    "      break\n",
    "  return root, current\n",
    "\n",
    "if 'ROOT_DIR' not in globals():\n",
    "\tROOT_DIR, EXPERIMENT_DIR = get_project_info()\n",
    "\tif str(ROOT_DIR) not in sys.path:\n",
    "\t\tsys.path.append(ROOT_DIR)\n",
    "\tif Path.cwd() != ROOT_DIR:\n",
    "\t\tos.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a46f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toy_transformers.data import tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251c9d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toy_transformers.utilities.reproducibility import set_all_seeds\n",
    "\n",
    "SEED = 42\n",
    "set_all_seeds(SEED, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb02006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toy_transformers.data import bpe\n",
    "from toy_transformers.utilities import io\n",
    "from toy_transformers.data import tokenization\n",
    "\n",
    "from toy_transformers.data.dataset import create_dataloader_for_epoch\n",
    "\n",
    "vocab = bpe.Vocabulary.from_state_dict(\n",
    "  io.load(EXPERIMENT_DIR / \"artifacts/vocab256\")\n",
    ")\n",
    "data = tokenization.TokenizedData.from_state_dict(\n",
    "\tio.load(EXPERIMENT_DIR / \"artifacts/data\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d0fb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3691ecde42114d39565b\n",
      "ed333c17b328d7c14d34\n",
      "205fbf29b5307e898b73\n",
      "1fff2261365272f16253\n",
      "e79de0e032f63337363b\n",
      "f1c6f94ccd994dd517ab\n",
      "ce4904eccff3145c2c16\n",
      "7fc928263a204ee9cb6d\n",
      "ec41a7091d6822e0e065\n",
      "eca1afd7422eafa7d8e0\n"
     ]
    }
   ],
   "source": [
    "# test random\n",
    "CHARS = \"0123456789abcdef\"\n",
    "for epoch in range(10):\n",
    "  train_loader = create_dataloader_for_epoch(\n",
    "    dataset=data, \n",
    "    epoch=epoch, \n",
    "    base_seed=SEED, \n",
    "    block_size=1, \n",
    "    batch_size=1, \n",
    "    shuffle=True, \n",
    "    drop_last=True,\n",
    "    pin_memory=False\n",
    "\t)\n",
    "  i_loader = iter(train_loader)\n",
    "  l = []\n",
    "  for i in range(10):\n",
    "    v1, v2 = next(i_loader)\n",
    "    l.append(v1.item())\n",
    "    l.append(v2.item())\n",
    "  print(\"\".join([CHARS[v % 16] for v in l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a12cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbae6d0cb06c75501f89fb2f4d5b24f91c6ee953080226c833786f09a769c46c\n"
     ]
    }
   ],
   "source": [
    "from toy_transformers.models import gptv1\n",
    "import pickle\n",
    "import hashlib\n",
    "\n",
    "# Model configuration\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "config = gptv1.GPTv1Config(\n",
    "    batch_size=64,\n",
    "    block_size=128,\n",
    "    n_heads=8,\n",
    "    n_embed=288,\n",
    "    n_layers=6,\n",
    "    dropout=0.2,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Create model (will use global random seed for weight initialization)\n",
    "model = gptv1.LanguageModel(\n",
    "    vocab_size=len(vocab.tokens),\n",
    "    config=config\n",
    ").to(device)\n",
    "\n",
    "state = model.state_dict()\n",
    "state_bytes = pickle.dumps({k: v.cpu().numpy() for k, v in state.items()})\n",
    "model_init_hash = hashlib.sha256(state_bytes).hexdigest()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
