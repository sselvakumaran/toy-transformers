{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bb403d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from torch.amp import autocast\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from models import gptv2 as transformer\n",
    "from utilities import text_cleaning, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13846cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.069m\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 128\n",
    "device = \"mps\"\n",
    "config = transformer.GPTv2Config(\n",
    "\tvocab_size=vocab_size,\n",
    "\tdevice=device,\n",
    ")\n",
    "m = transformer.LanguageModel(config)\n",
    "print(m.get_num_parameters(as_str=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "373e8fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../../data/gutenberg/interpretation-of-dreams.txt\"\n",
    "input_file = open(filepath, 'r', encoding='utf-8')\n",
    "raw_text = input_file.read()\n",
    "input_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50eec530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "from utilities import text_cleaning\n",
    "from utilities import tokenizer as tokenizer\n",
    "text = text_cleaning.gutenberg_cleaning(raw_text)\n",
    "td = tokenizer.create_tokenizer(text, num_tokens=vocab_size)\n",
    "print(len(td.token_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "475c7eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters, idx_to_token, token_to_idx = td\n",
    "encode = tokenizer.get_encoder(td)\n",
    "decode = tokenizer.get_decoder(td)\n",
    "data = torch.tensor(encode(text), dtype=torch.long).to(device=device)\n",
    "\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "block_size, batch_size = config.block_size, config.batch_size\n",
    "def get_batch(split):\n",
    "  data = train_data if split == 'train' else val_data\n",
    "  idxs = torch.randint(len(data) - block_size, (batch_size,), device=device)\n",
    "  x = torch.stack([data[i:i+block_size] for i in idxs])\n",
    "  y = torch.stack([data[i+1:i+block_size+1] for i in idxs])\n",
    "  return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_val_loss(model):\n",
    "  model.eval()\n",
    "  X, Y = get_batch(\"val\")\n",
    "  _, loss = model(X, Y)\n",
    "  model.train()\n",
    "  return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53aa93b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "m = transformer.LanguageModel(config).to(device=device)\n",
    "m.compile()\n",
    "\n",
    "optimizer = m.get_optimizer(weight_decay=0.001, lr=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "\toptimizer, mode='min', factor=0.1, patience=10\n",
    ")\n",
    "\n",
    "@torch.compile(fullgraph=False)\n",
    "def opt_step():\n",
    "\toptimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab190009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0000/2000] train: 1.56203 val: 1.43995\n",
      "[0025/2000] train: 1.53058\n",
      "[0050/2000] train: 1.53291 val: 1.42517\n",
      "[0075/2000] train: 1.49940\n",
      "[0100/2000] train: 1.53825 val: 1.41278\n",
      "[0125/2000] train: 1.56428\n",
      "[0150/2000] train: 1.49303 val: 1.40699\n",
      "[0175/2000] train: 1.48880\n",
      "[0200/2000] train: 1.48049 val: 1.44439\n",
      "[0225/2000] train: 1.45329\n",
      "[0250/2000] train: 1.55818 val: 1.41211\n",
      "[0275/2000] train: 1.52154\n",
      "[0300/2000] train: 1.45626 val: 1.40284\n",
      "[0325/2000] train: 1.49426\n",
      "[0350/2000] train: 1.51967 val: 1.35883\n",
      "[0375/2000] train: 1.52190\n",
      "[0400/2000] train: 1.57727 val: 1.38528\n",
      "[0425/2000] train: 1.50729\n",
      "[0450/2000] train: 1.46462 val: 1.42151\n",
      "[0475/2000] train: 1.42498\n",
      "[0500/2000] train: 1.43754 val: 1.37456\n",
      "[0525/2000] train: 1.47349\n",
      "[0550/2000] train: 1.51410 val: 1.39318\n",
      "[0575/2000] train: 1.41240\n",
      "[0600/2000] train: 1.44399 val: 1.37550\n",
      "[0625/2000] train: 1.48936\n",
      "[0650/2000] train: 1.46773 val: 1.39262\n",
      "[0675/2000] train: 1.43367\n",
      "[0700/2000] train: 1.44610 val: 1.38957\n",
      "[0725/2000] train: 1.42588\n",
      "[0750/2000] train: 1.43752 val: 1.35982\n",
      "[0775/2000] train: 1.44593\n",
      "[0800/2000] train: 1.46031 val: 1.39004\n",
      "[0825/2000] train: 1.38808\n",
      "[0850/2000] train: 1.43412 val: 1.36672\n",
      "[0875/2000] train: 1.44386\n",
      "[0900/2000] train: 1.45344 val: 1.35812\n",
      "[0925/2000] train: 1.43694\n",
      "[0950/2000] train: 1.42748 val: 1.37556\n",
      "[0975/2000] train: 1.45159\n",
      "[1000/2000] train: 1.39957 val: 1.35717\n",
      "[1025/2000] train: 1.37534\n",
      "[1050/2000] train: 1.37858 val: 1.40913\n",
      "[1075/2000] train: 1.40997\n",
      "[1100/2000] train: 1.42307 val: 1.40990\n",
      "[1125/2000] train: 1.39973\n",
      "[1150/2000] train: 1.41633 val: 1.37475\n",
      "[1175/2000] train: 1.42377\n",
      "[1200/2000] train: 1.41311 val: 1.36253\n",
      "[1225/2000] train: 1.36836\n",
      "[1250/2000] train: 1.44258 val: 1.37210\n",
      "[1275/2000] train: 1.37993\n",
      "[1300/2000] train: 1.38309 val: 1.32999\n",
      "[1325/2000] train: 1.43583\n",
      "[1350/2000] train: 1.37766 val: 1.33183\n",
      "[1375/2000] train: 1.36145\n",
      "[1400/2000] train: 1.40612 val: 1.40304\n",
      "[1425/2000] train: 1.37291\n",
      "[1450/2000] train: 1.39620 val: 1.38581\n",
      "[1475/2000] train: 1.36745\n",
      "[1500/2000] train: 1.33793 val: 1.31791\n",
      "[1525/2000] train: 1.37211\n",
      "[1550/2000] train: 1.37503 val: 1.33817\n",
      "[1575/2000] train: 1.37325\n",
      "[1600/2000] train: 1.35729 val: 1.39240\n",
      "[1625/2000] train: 1.32244\n",
      "[1650/2000] train: 1.35271 val: 1.30975\n",
      "[1675/2000] train: 1.34458\n",
      "[1700/2000] train: 1.39321 val: 1.34186\n",
      "[1725/2000] train: 1.38119\n",
      "[1750/2000] train: 1.36220 val: 1.28412\n",
      "[1775/2000] train: 1.40343\n",
      "[1800/2000] train: 1.36574 val: 1.37945\n",
      "[1825/2000] train: 1.30740\n",
      "[1850/2000] train: 1.34361 val: 1.34820\n",
      "[1875/2000] train: 1.30802\n",
      "[1900/2000] train: 1.33510 val: 1.34136\n",
      "[1925/2000] train: 1.35071\n",
      "[1950/2000] train: 1.36535 val: 1.32201\n",
      "[1975/2000] train: 1.36683\n"
     ]
    }
   ],
   "source": [
    "num_steps = 2000\n",
    "for step in range(num_steps):\n",
    "\txb, yb = get_batch('train')\n",
    "\tm.train()\n",
    "\twith autocast(device_type=\"mps\", dtype=torch.float16):\n",
    "\t\tlogits, loss = m(xb, yb)\n",
    "\toptimizer.zero_grad(set_to_none=True)\n",
    "\tloss.backward()\n",
    "\topt_step()\n",
    "\ttrain_loss, val_loss = loss.item(), None\n",
    "\tif step % 50 == 0:\n",
    "\t\tval_loss = estimate_val_loss(m)\n",
    "\t\tscheduler.step(val_loss)\n",
    "\t\tprint(f\"[{step:04d}/{num_steps}] train: {train_loss:01.05f} val: {val_loss:01.05f}\")\n",
    "\telif step % 25 == 0:\n",
    "\t\tprint(f\"[{step:04d}/{num_steps}] train: {train_loss:01.05f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d49e656a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function of the dream about comanding the took from which really furnishes the expectation of the dream and stimulus, on unmertake if it frequencess the omissions of condensations appears to be continued in our dreams, just well found up too up the fact that points into the dream the absurd judgment those have something (p. 286). It is as I shall represent understand.\n",
      "In the dream about This It larrge, which originates were presented by a sexual sensation given into a bsench performance to form as itself of the au\n"
     ]
    }
   ],
   "source": [
    "seed = \"The \"\n",
    "idx = torch.tensor([encode(seed)], dtype=torch.long, device=device)\n",
    "print(seed, end=\"\", flush=True)\n",
    "for token in m.generate(idx, max_new_tokens=400):\n",
    "\tv = token.item()\n",
    "\tprint(decode([v])[0], end=\"\", flush=True)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
